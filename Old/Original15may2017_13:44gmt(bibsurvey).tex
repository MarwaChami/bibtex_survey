\documentclass[a4paper,10pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{booktabs}
\usepackage{multirow}
\title{Bibliography and Criteria Definitions}
\author{}

\begin{document}

\maketitle

\section{Latency}
Latency is one of widely used performance metrics in computer networks \cite{SiHa15}. It is defined as the delay that occurs in data communication over a network. In SDNs, frequent message exchanges between switches and controllers and between different controllers (if there are many) are essential to carry out all SDN functions. Thus, network latency can be an important criterion to take into consideration when optimizing SDN networks, namely when optimizing the controller placement. The overall latency consists of packet transmission latency, propagation latency, switch queuing latency, and controller processing latency \cite{WaZh17}. The packet transmission latency is related to the packet size and the data-rate of the link. The propagation latency is proportional to the distance between two communication nodes. The switch queuing latency is the delay caused by a link congestion. The controller processing latency consists of the delay affected by the controller load. However, most of the works presented in the literature to solve the CPP investigate the case of Wide Area Networks (WANs), where only propagation and processing latencies dominate because of the relatively small control message size in SDN and the assumed large capacity of control links. In this section, we mainly present the papers proposing solutions to the CPP by minimizing the propagation latency between switches and controllers as well as inter-controllers latency. Other works that minimize the propagation latency along with processing latency are also presented.


%The network latency may include the propagation latency between the switches and the controller they are assigned to, the propagation latency between controllers, the controller processing latency or a sum of different definitions. When the controller placement problem was introduced in \cite{HeSh12}, both average and worst-case propagation latencies between controllers and switches were minimized. In the following, the term "latency" stands for the propagation latency, which is linear to distance, between controllers and switches. Any other use will be pointed out, such as the inter-controller latency, the hop count between nodes, or the processing latency related to the controller load.   


\subsection{Papers}
\cite{HeSh12}: The controller placement problem (CPP) was firstly introduced by Heller et al. \cite{HeSh12}. The authors investigate node to controller latency and propose an optimal placement by directly considering the metrics on all possible combinations of controllers. Both k-median and k-center problems are investigated to minimize average and worst-case latencies, respectively. WAN networks from Topology Zoo are considered and simulated in Matlab to investigate the optimal controllers placement. Analysis considering other metrics such as reaction delay, fault discovery, propagation efficiency, availability and bandwidth processing are discussed when only one controller is deployed. The authors observe that if the network is large, it is necessary to locate more than one controller. For networks with technology such as SONET, it is sufficient to use only one controller to meet response-time goals. Consequently, it is concluded that the location and number of controllers depend on the network topology used. The authors also note that the average latency with a random placement is 1.4 to 1.7 larger than that of the optimal placement, while this ratio is between 1.4 and 2.5 for worst-case latencies. 

\cite{HeSh12}:For WANs, the best driver location depends on the propagation latency considering limiting control reactions. Having a remote controller, this can be executed at a speed and reasonable stability.
For this work, the authors compared the locations of drivers using latency node controller to the fundamental limits imposed in response delay, fault-finding and event propagation efficiency. There are other important metrics such as availability status and equity, processing and bandwidth, but the main focus is the latency biggest problem for WANs. Additionally, the authors used two kinds of metrics Average Latency-case and worst-case latency within a topology Internet2 OS3E topology.
Proponents of this article show the response to deploy many drivers depends on the desired reaction limits the choice in the metrics and the own network topology. Further suggest that the plans fully distributed control are more resistant to failures planes uncoupled control, but the problems of route flapping.
[USTA]

\cite{HeSh12}:In traditional networks, the control plane and the data plane are closely related, the controller is fully distributed, that is, each network device is responsible for deciding where to direct packets and carry also carry the mechanism to receive and send them to the destination. SDN architecture in both planes are separated, the control logic moves to an external controller. Thus, the functions of the elements become more engaged in each of the planes, the data plane devices made only forwarding packets without regard for logic control.
When the control plane is decoupled raised questions about the reliability, scalability and performance compared to traditional architectures network. To quantify the performance and fault tolerance, the authors focused on two questions: how many controllers are needed? and where they should be located ?. The answers to these questions along with the choice of design are the problem of the location of the driver.
This document the driver location is optimized in order to minimize propagation delays or latency node-controller WANs. They analyzed the behavior topology InternetZoo Internet2 and topologies using metrics defined "Average-case Latency" and "Worst-case latency". They showed that the random location of the driver is not optimal, the number of drivers depends on the topology and there are no rules location of the driver that apply to all networks, but must use a method to determine the best location. [USTA]

%\cite{HeSh12}: The controller placement problem (CPP) was firstly introduced by this paper. Heller et al. investigate node to controller latency and propose an optimal placement by directly measuring the metrics on all possible combinations of controllers. Both k-median and k-center problems are investigated to minimize average and worst-case latencies, respectively. Optimal controllers placements are presented for the Internet2 OS3E Topology. Analysis of this topology along with others from the Internet Topology Zoo are presented to respond various questions about the minimum required number of controllers, how does placement affect latency and the trade-offs to make. The authors note that the average latency with a random placement is 1.4 to 1.7 larger than that of the optimal placement, while this ratio is between 1.4 and 2.5 for worst-case latencies. They also point out that "for many networks, multiple controllers are not strictly necessary to meet response-time goals". 

%\cite{HeSh12}: In a traditional network, the control plane is integrated with the data plane, it is sought to decouple the planes of data and control forwarding in SDN networks. The performance of the network can be improved by choosing carefully the location of controllers. This proposes a flexible, evolutionary and convergent network. Those who do not agree, say there will be problems about decision latency, availability, and scalability. For this reason, two questions are asked: how many controllers are necessary and where should they be placed?

%For the study of the location of the controller, WAN networks from Topology ZOO were considered and simulated in Matlab. The where the best location minimizes the propagation delays. The main metric is "forwarding device to controller latency" and other metrics were as well considered: reaction delay, fault discovery, propagation efficiency, availability and bandwidth processing.
%The results indicated that the location of the controller affects the performance of the network and most of the locations are not efficient (in terms of reaction delay,fault tolerance, latency inter controller]), only a few solutions in the network are optimal. It was also observed that if the network is large, it is necessary to locate more than one controller. For networks with technology such as SONET, it is sufficient to use only one controller. Finally, it is concluded that the location and number of controllers depend on the network topology used.[USTA]


\cite{WaZh17}: This paper presents a survey on the controller placement problem. The authors draw a taxonomy based on the objectives of the research works in this field. Models, objectives and solutions are elaborated for each category. [more details to justify our contribution.] 

This paper also proposes an algorithm to address the controller placement problem in the aim of minimizing the maximum latency between controllers and switches. The proposed approach, called Clustering-Based Network Partition Algorithm, iteratively partitions the network into different subnetworks. For each subnetwork, a centroid that has the minimum sum physical distances to all nodes is selected. The performance of the proposed algorithm is evaluated in comparison to the k-center and k-means approaches. The Internet2 OS3E topology was chosen, where the nodes coordinates were obtained from Google Map and the distances of the links were calculated using the "haversine" formula. The shortest path distance was calculated using Dijkstra's algorithm. Simulations show that the proposed approach ensures smaller maximum latency between the controller and associated switches than the one achieved by both k-center and k-means. 


%\cite{WaZh17}:This article firstly examines the latest methods related to CPP in SDNs . Secondly, it proposes an approach to reduce latency between controllers and forwarding devices.

%The controller problem has caused a lot of research, this directly affects SDN networks, in metrics like a performance, fault tolerance, resilience, latency and others. The authors propose in this paper a "Clustering-Based Network Partition Algorithm (CNPA)", this algorithm divides networks into subnets and locates the controllers in the subnetworks, in order to reduce latency between controller-to-controller and controller to forwarding devices.

%The algorithm was simulated in Matlab, with an OS3E topology. Results showed that the network latency between controllers and the forwarding devices, the cost of implementation and energy consumption are minimized, while the reliability and resilience are maximized.[USTA]



\cite{SaSa16}: This paper aims to find out the controller placement that minimizes the sum of switch-to-controller and inter-controllers distances. The authors compare a spectral clustering algorithm that partitions the network into smaller domains for placing the controller, to k-median and k-center algorithms. Simulations on three topologies (TataNld, Fortnet and DeutscheTelkom) show that the graph partitioning technique performs better than k-median and k-center algorithms. 


\cite{YaBi14}: This paper introduces the capacitated controller placement problem (CCPP) minimizing the maximum latency between the switches and their assigned controller subject to controller capacity. Thus, the controller load formed by the processing of PACKET\_IN events, delivering the events to the applications, communicating with other controllers and maintaining the view of the local network partition, has to be maintained under a capacity limit.
The problem being NP-hard, a capacitated k-center strategy is proposed to solve it. More specifically, the authores use the algorithm proposed in \cite{OzPi06} to solve the capacitated vertex p-center problem. An Integer Programming model is also used to find the minimal number of controllers with a specified radius, where the radius denotes the maximum propagation latency between switches and the assigned controller. The proposed algorithm is compared to the classical k-center approach in various topologies chosen from the Topology Zoo. The proposed strategy can reduce the number of controllers required to avoid overload as well as the load of the heaviest-load controller, when compared with k-center. Also, it has smaller radius than using dynamic controller provisioning or dynamic scheduling strategy in k-center placement. 


%\cite{YaBi14}: This paper minimizes the maximum latency between the switches and their assigned controller subject to controller capacity. The problem being NP-hard, a capacitated k-center strategy is proposed to solve it. An Integer Programming model is also used to find the minimal number of controllers with a specified radius, where the radius denotes the maximum propagation latency between switches and the assigned controller. The proposed algorithm is compared to the classical k-center approach in various topologies chosen from the Topology Zoo. The proposed strategy can reduce the number of controllers required to avoid overload as well as the load of the heaviest-load controller, when compared with k-center. Also, it has smaller radius than using dynamic controller provisioning or dynamic scheduling strategy in k-center placement. 

%\cite{YaBi14}:This article defines the capacitated controller placement problem (CCPP)", considering the propagation latency between controller and forwarding devices, and the load of the controllers.

%A load of a controller is made up of four parts: first, packages of input and delivery to the applications. Second, the partition of the local network. Third: partition of the global view. Fourth, installation of the flow entries generated by the applications. When many input packets arrive at the controller, the performance and bandwidth decrease.
%The objective is to consider the load of the controller, therefore an integer propagation algorithm is used to find the minimum number of controllers, "Topology Zoo" was used (82 of 261 topologies).

%The results display a reduction in the number of controllers, also the load of the active controllers was reduced.[USTA]

\cite{YaBi14}:Yao et. al proposed a more extensive to the problem by Heller. The article proposes the problem of qualified location of the driver or WACC) Capacited controller placement problem), based on the exact algorithm. This algorithm works in two phases described below i) Find the minimum number of drivers for a specific radius ii) The radius is increased from Lower bound (south) until the driver location is obtained; considering radius defined by the maximum distance proponents / latency each switch assigned to each controller. For this work, they are considered the metric load controller and network radio. This algorithm was tested in 82 of the 26 topologies Topology Zoo. According to the results,
Limited capacity of the server: memory, broadband access, processors and other resources: a basic server limitations as expected. Because of this, you may be limited to the server to handle multiple routers. You consider another controller Cluster, provide better performance and scalability, but significantly increase the cost of its implementation and operation.
Message processing latency: Based on the results of work (Tootoonchian A., S. Gorbunov Ganjali Y., M. Casado, and R. Sherwood, "On controller performance in software-defined networks," in Proc. HotICE, 2012, pp. 7- 10.), when the load reaches a threshold controller, the latency controller increase substantially. In these cases the processing latency will be negligible compared propagation latency back and forth.
Failures: High load drivers always are more likely to fail, because they have fewer resources to handle multiple errors and is more likely to be attacked. In some cases, the failure of high load controller can cause cascading failures of other drivers.[USTA]

\cite{HuJo15}: This paper minimizes the propagation latency taking into consideration the traffic load of switches in terms of number of flows.  The contribution of this paper includes two parts. In a first step, the proposed method partitions the network into sub-regions and the location of controllers is chosen such as the maximum number of switches can be operated and the maximum latency can be minimized,  using the Bowyer-Watson algorithm. In a second step, the proposed approach called LiDy dynamically adapts the number of controllers as the traffic load of switches varies using a dynamic flow management algorithm.

Simulations show that the proposed algorithm requires a lower number of controllers to balance the same traffic load compared to YBLG proposed in \cite{YaBi14}, ensuring better control plane utilization while maintaining the latency within a maximum bound. 

The drawback of LiDy being its complexity, Huque et al. present LiDy+ in \cite{HuSi17} to reduce the time complexity of their former solution, while achieving similar performance in terms of latency, controller utilization, power consumption, and cost. The main difference between the two algorithm leads in the manner to split the network into sub-regions. More specifically, LiDy+ runs the smallest enclosing risk algorithm which enables a lower complexity than the triangular decomposition proposed by LiDy. LiDy+ is also applicable at large scale.

\cite{HuJo15}:Huque et al. introduced a dynamic solution to the problem of driver location using Lydi, which is an algorithm that combines a separate module for the driver location and another module management algorithm dynamic flow. In the algorithm latency constraint controller it is mainly used - switches, as an input and output module driver location, maximizing the number of switches that can be operated by each selected under the constraint of predefined location latency. Following this, the solution adapts the number of drivers each driver module to vary or handle the traffic load (for this paper is referred to as the number of new flows found for each switch). Given this,
Controller module: Use a limited number of driver modules

Location search without restrictions: Select the location of the driver of a set of selected locations (locations of switches). But Lidy searches the entire region containing the locations of the switches for the driver location.

DYNAMIC TRAFFIC: Considering both optimization criteria listed above, the load switches varies with time, the location must be constantly replaced; however these two criteria are treated separately.

The authors compared this algorithm with a call they say relevant solution for CPP (YBLG), demonstrating that Lidy requires half of controllers, ensuring latency and considering that is the first algorithm able to provide the solution to CPP considering the load dynamic switches. 

%\cite{HuJo15}: The contribution of this paper includes two parts. In a first step, the authors investigate the controller placement problem under a predefined switch to controller latency constraint. Secondly, they dynamically adapt the number of controllers as the traffic load (number of flows) of switches varies. Consequently, the latency and the load of switches are separately considered in the proposed solution, called LiDy. The authors also propose to use a limited number of controller modules, where each controller module is a set of controllers. 

%Concerning the controller module placement, the network is firstly partitioned into sub-regions based on a maximum latency bound. The optimal placement of the controller module is found using the Bowyer-Watson algorithm.

%Simulations show that the proposed algorithm requires a lower number of controllers to balance the same traffic load compared to YBLG proposed in \cite{YaBi14}, ensuring better control plane utilization while maintaining the latency within a maximum bound. 

%The drawback of LiDy being its complexity, Huque et al. present LiDy+ in \cite{HuSi17} to reduce the time complexity of their former solution, while achieving similar performance in terms of latency, controller utilization, power consumption, and cost. The main difference between the two algorithm leads in the manner to split the network into sub-regions. More specifically, LiDy+ runs the smallest enclosing risk algorithm which enables a lower complexity than the triangular decomposition proposed by LiDy.

%\cite{HuJo15}:The CPP normally considers fixed traffic and there are not currently solutions to find the load.

%The dynamically focused CPP is displayed and the driver is located dynamically and determines the number of controllers in the network, necessary to support the load. The authors propose an algorithm of placement of the controller, combined with a dynamic flow management algorithm called LiDy, the results show a lower latency between controller and forwarding devices.[USTA]

%\cite{HuSi17}:The CPP is one of the biggest challenges for big networks in sdn, Md Tanvir [et all] propose choose controller location for minimize the latency between forwarding devices and controllers and determine the number of controllers in SDn network.

%The authors will consider the dynamic charge. They created the algorithm Lidy + (Conformed for O (n2): Algorithm for discovery optimal Boolean Pattern paris and an algorithm to dynamic flow), it was tested by a topology connected to 600 users.

%The results evidenced are: low quantity of controllers in the network tested, very low cost of energy and maintenance respect of the previous algorithm Lidy.[USTA]


\cite{GaWa15}: This paper aims to minimize the global propagation latency, i.e. the sum of switches to controllers latency and the inter-controllers latency, subject to the load limitation of controller. The authors propose a particle swarm optimization (PSO) algorithm to solve the problem. However, the evaluation of the proposed algorithm is not very clear since it is based on the comparison with other algorithms solving different objective functions. 


%\cite{GaWa15}: This paper proposes a particle swarm optimization (PSO) based algorithm to solve the controller placement problem, considering latency from switches to controller, latency between controllers and the capacities of the controllers. The idea is to minimize the global latency subject to controllers load. Initially, the controllers are placed using a PSO algorithm and then, the switches are assigned to the nearest controller according to the minimum latency. Once the loads are computed, the controller with a load that exceeds its limitation assigns the switch to the nearest controller. This operation is repeated until convergence. The proposed algorithm is compared with a greedy algorithm (GL) and integer linear programming (ILP) algorithm proposed in \cite{YaBi14}. Simulation results show that PSO and ILP produce a better solution than GL but consume much more processing time than it. PSO converges slightly faster than ILP for large-sized networks.



\cite{KiRa16}: Killi and Rao present a mathematical model that minimizes the worst-case switch-to-controller latency in the case of controller failure, subject to the controller capacity. The authors admit that in case of controller failure, reassigning the switches of this controller to another one may drastically increase the worst-case latency. To avoid this problem, they maintain a list of backup controllers for every switch taking into account the worst-case switch-to-controller latency and the capacity of controllers. This helps in reassigning the switches of the failed controller to the next available controller of the list. The authors assume that the switches have failure foresight by knowing in advance the unavailability of controllers, which is a strong assumption.  

The proposed scheme, called Failure Foresight Capacitated Controller Placement (FFCCP), is also extended to a Combined Objective FFCCP (CO-FFCCP), minimizing the sum of worst-case latencies from each switch to each controller. The proposed schemes are presented as an ILP and solved using CPLEX optimizer. Furthermore, they are evaluated on several WAN topologies and compared to a Capacitated Controller Placement (CCP) algorithm that minimizes the worst-case latency in failure free case at the expense of increasing the worst case latency in case of failures. Simulation results show that in the case of controller failure,  there is a drastic increase in the worst-case latency of CCP and it is much higher than that of FFCCP. This latter performs better than CO-FFCCP which is not optimized for failures alone, but it is optimized for the worst-case latencies with and without failures together. 

The authors extend their work in \cite{KiRa17}, where they propose a controller placement strategy that considers capacity and reliability of controllers, and also plans ahead for controller failures. More specifically, the proposed algorithm allows to generate a list of backup controllers for every switch in order to reassign it to one of these controllers in case of failure. The proposed scheme entitled Capacitated Next Controller Placement (CNCP) minimizes the sum of the latency from the switch to its assigned controller and the latency from this controller to the backup controllers, subject to controller capacity. A simulated annealing heuristic is proposed to solve the problem. CNCP is compared to the Capacitated Controller Placement algorithm that minimizes the worst-case latency in the failure-free case subject to controller capacity. Simulation results show that CNCP performs better than CCP in case of failures. The presented heuristic is also proven to converge to the optimal value with a small gap, while taking the half of the time required by an exact solution. 

%but without assuming the failure foresight of switches.
%TALK ABOUT FAILOVER??

\cite{KiRa16}:Killi and Rao presented a mathematical model called On the load balanced controller placement problem in Software defined networks (FFCCP) that prevents a drastic increase in latency worst case occurs when a driver fails. The objective of the model is to minimize the worst-case latency (worst-case latency) between switches and backup controllers through early planning failures. In addition, they show a variant of the model that minimizes the worst case latency with and without faults, called Combined Objective-FFCCP (CO-FFCCP). They avoided disconnections due to faulty drivers by maintaining a list of reference drivers K (> 1) for each switch, where K is a constant determined by the network designer.
They evaluated the formulation WAN, AT&T (25 nodes, 114 links), GEANT (40 nodes, 122 links) and SURFNET (50 nodes, 146 links), Internet Topology Zoo (12) topologies. The results showed that the FFCCP and CO-FFCCP outperformed the CCP in case of failure. The simulation allowed to see the CO-FFCCP worked better than FFCCP and near the CCP in the absence of failures. The number required by FFCCP and CO-FFCCP controllers is greater than that maintained CCP reference drivers for each switch K, while maintaining only one CCP.[USTA]

\cite{KiRa17}:Killi and Rao propose a strategy to solve the problem of the location of the driver called Trained Placing the Next Controller (Controller Placement Capacitated Next, CNCP) which considers the reliability (reliability) and capacity (capacity) drivers. In addition planning failures drivers to avoid frequent administrative intervention, the dramatic increase in latency and disconnections. To do this, each switch is assigned a first reference driver with sufficient capacity corresponding its closest driver and a second reference driver with sufficient capacity is the closest to the first reference driver controller. CNCP formulated as a linear program mixed integer numbers (MILP) using binary variables three indices that can be easily extended to the target average latency. The objective is to minimize the total latency from the switch to the first reference driver and latency from the first controller to the second controller reference reference.
The CNCP is evaluated in several Internet networks Topology Zoo [34], including AARNET (19 nodes), AT & T (25 nodes), BTNA (35 nodes) GEANT (40 nodes), IRIS (50 nodes) and SURFNET (50 nodes ) and its performance compared to the CCP.
They assumed that the driver software running on a server with a bandwidth of 10 Gbps maximum access. The capacity of each controller is set to 7.8 * 10 ^ 6 packets / second because the size of a packet is 160 bytes according to OpenFlow v 1.2 specification.
The simulation results show the proposed works better than CCP method in case of failure.[USTA]






\section{Resilience}
\subsection{Definition}
There are several definitions of resilience which differ more or less in their meanings. In the following, we shall adopt the definition proposed by \cite{StHu07}, which claims that   "resilience is the ability of the network to provide and maintain an acceptable level of service in the face of various faults and challenges to normal operation".  Any other sense considered in the contributions will be pointed out.

%, such as unusual but legitimate traffic load, high-mobility of nodes and subnetworks, weak, asymmetric, and episodic connectivity of wireless channels, unpredictably long delay paths, attacks against the network, large-scale natural disasters, failures due to mis-configuration or operational errors, or natural faults of network components."
 

%Survivability is the capability of a system to fulfill its mission in a timely manner, even in the presence of attacks or failures [CMU SEI], including large scale natural disasters.

%Disruption tolerance is the ability for end-to-end applications to operate even when network connectivity is not strong (weak, episodic, or asymmetric) and the network is unable to provide stable end-to-end paths. 
%Thus survivability and disruption tolerance are necessary but not sufficient for resilience.

%Fault tolerance the ability of a system or component to continue normal operation despite the presence of hardware or software faults [IEEE].
%Fault tolerant systems are generally engineered only to tolerate isolated random natural failures. Thus, fault tolerance is necessary but not sufficient for survivability (and therefore resilience). 

%Though a single controller could be enough in most topologies, from a latency point-of-view, many more controllers are necessary to meet resilience requirements. Resilience is the ability of a network to recover after node and links failures. 

\subsection{Papers}
\cite{ZhBe11}: Although the CPP was assigned to Heller \cite{HeSh12}, this paper which was published one year before Heller's work, treats the same problem, i.e. controller location, but in the aim to maximize the network resilience. The authors propose a min-cut based graph partitioning algorithm for controller placement to maximize the resilience of the network. They consider different types of failures, namely links and nodes failures. The partitions are identified with minimum cuts across boundaries, i.e. insuring a minimum connectivity between clusters. After the partitioning, the controller is placed in the centroid of the partition to guarantee the shortest path length to all switches in the same cluster. They evaluate their approach using a perl-based simulation tool. The simulations show the impact of controller placement on resilience, and prove that the proposed algorithm outperforms the random and greedy based placements in terms of failure probability in the Abilene topology composed of 10 nodes. 


\cite{MuOl14}: Müller et al. investigate the same problem in \cite{ZhBe11} proposing "Survivor": a resilient framework which reinforces the connectivity between controllers and switches, taking more routes, avoiding the overload of the controller and improving the failover by composing a list of backup controllers for each device in the network. The proposed approach encompasses two phases: Firstly, the controller placement problem is investigated, such that capacity constraints are satisfied and connectivity is maximized, by choosing positions that yield the highest number of node-disjoint paths between the controller and the switches. The problem is presented as an Integer Linear Programming, where the capacity is defined as the maximum number of requests that a controller can handle per second. Secondly, a list of backup controllers for each device in the network is specified. Two heuristics for selecting backups during failover are proposed: One based on proximity and the other based on residual capacity. This method is evaluated with various simulated topologies from Topology Zoo, mainly the Internet2 OS3E topology considering 10 nodes and 5 links, RNP with 27 nodes and 15 links, and Grant considering 40 nodes and 61 links.   The authors compare by simulations their work to the algorithm proposed in \cite{ZhBe11}. Many improvements of "Survivor" are noted: (a) considering multiple paths, i.e. exploring path diversity during placement, which reduces the chance of connectivity loss; (b) taking into consideration the capacity to avoid controllers overload; (c) improving smart recovery mechanisms thanks to the proposed heuristic for selecting backups during failover.

%\cite{MuOl14}: This paper proposes a controller placement strategy that improves the network resilience. The goal is to maximize the connectivity while satisfying the  placement constraints. The authors use controller distribution and controller replication techniques to increase the resilience of SDNs. Their study encompasses two phases: Firstly, the controller placement problem is investigated, such that capacity constraints are satisfied and connectivity is maximized, by choosing positions that yield the highest number of node-disjoint paths between the controller and the switches. The problem is presented as an Integer Linear Programming, where the capacity is defined as the maximum number of requests that controller can handle. Secondly, a list of backup controllers for each device in the network is specified. Two heuristics for selecting backups during failover are proposed: One based on proximity and the other based on residual capacity. The authors compare by simulations the proposed strategy "Survivor" to the one proposed by Zhang et al. \cite{ZhBe11}, on different topologies, mainly GEANT. Many improvements of "Survivor" are noted: (a) considering multiple paths, i.e. exploring path diversity during placement, which reduces the chance of connectivity loss; (b) taking into consideration the capacity to avoid controllers overload; (c) improving the covering state of the network thanks to the proposed heuristic for selecting backups during failover.

%\cite{MuOl14}:In SDN networks, the controllers must be connected to the forwarding devices to avoid harmful events in the network. Problems in the network can isolate forwarding devices and overload in the network.

%[Lucas Müller] et al. propose "survivor", which reinforces the connectivity from controller to forwarding devices, taking more routes, avoiding the overload of the controller and improving the failover by taking routing lists as backup copies, thanks to a heuristic algorithm that evaluates the placement Current controllers and determine if they should change position or not, make comparisons between controllers. This method was evaluated with the topology of Internet 2, taken from Topology Zoo, considering (10 nodes, 5 links), RNP (27 nodes, 15 links) and Grant (40 nodes, 61 links).

\cite{ViMa16}: In this paper, two strategies for controller placement in the aim of providing protection against link and node failures while minimizing controller to switch latency  are proposed. In the first strategy, every node must be connected to its assigned controller over two disjoint paths. In the second one, every node must be connected to two different controllers over two disjoint paths. The main idea of this work is to consider planning of the backups paths in advance. An optimization problem to find a controller placement that jointly optimizes working and backup paths is investigated for the two strategies. The problem is formulated as a Mixed Integer Linear Programming and the optimal placement is found using the Gurobi solver. The evaluation of performance metrics in several topologies shows that the working paths in the proposed strategies may be longer than in the unprotected case (without backup paths). This difference decreases as the number of controllers increases. Simulations also show that both strategies ensure lower control path loss and better control path availability than the unprotected case. The authors verify the feasibility of the solving time for the simulated topologies with single and double link failures. note that the solving time of both models is relatively fast but still unacceptable for online use with dynamic assignment based on traffic. However, this paper does not take into consideration the capacity constraints.

\section{Reliability}
\subsection{Definition}
Reliability is a measure of service continuity referring to the probability that a system remains operable in a given time frame \cite{Rak15}. 

%Reliability is a metric inversely proportional to the percentage of expected control path loss.  Where the control path loss is the number of broken control paths due to network failures.


\subsection{Papers}
%\cite{FaXi18}: Can't find it online.

\cite{HuWe13} and \cite{HuWa12}: SDN networks have the control plane separated from the data plane, this split presents reliability problems, the gap between the control layer and the data capacity results in a loss of packets. To face this problem,  given a failure of each component of the network, Hu et al. propose in \cite{HuWa12,HuWe13} an algorithm to determine how many controllers and how to connect them in order to optimize the reliability of the network. In this perspective, they introduce a metric called "the expected percentage of control path loss" and define it  as the number of broken control paths due to network failures. They define the control paths as the set of routes between controllers and switches as well as inter-controllers routes. The authors only analyze failure scenarios where at most one physical component fails at a time. They do not propose any control path protection mechanism assuming that when a physical component fails, the control paths traversing this component fail as well. The reliability-aware controller placement problem being NP-hard, two heuristics are proposed to solve the problem: l-w-greedy and simulated annealing. These algorithms are compared to an exhaustive approach, the brute force algorithm, as well as to a random placement algorithm. 

Firstly, the authors evaluate the performance of the various algorithms using the Internet2 OS3E topology. Simulations prove that the simulated annealing algorithm provides solutions that are close to optimal. Moreover, the authors expand their analysis to the Rocketfuel topology, in order to analyze the impact of controller number on reliability. To this aim, they consider only the simulated annealing algorithm and set fixed failure probabilities for each switch and each link. They observe that using too few or too many controllers reduces reliability. Simulations also show trade-offs between reliability and latencies in both topologies.


%The authors propose a reliable-aware controller placement by minimizing the expected percentage of control path loss, where the control path loss is the number of broken control paths due to network failures. They define the control paths as the set of routes between controllers and switches as well as inter-controllers routes. The authors only analyze failure scenarios where at most one physical component fails at a time. They do not propose any control path protection mechanism assuming that when a physical component fails, the control paths traversing this component fail as well. The reliability-aware controller placement problem being NP-hard, two heuristics are proposed to solve the problem: l-w-greedy and simulated annealing. These algorithms are compared to an exhaustive approach, the brute force algorithm, as well as to a random placement algorithm. 

%Firstly, the authors evaluate the performance of the various algorithms using the Internet2 OS3E topology. Simulations prove that the simulated annealing algorithm provides solutions that are close to optimal. Moreover, the authors expand their analysis to the Rocketfuel topology, in order to analyze the impact of controller number on reliability. To this aim, they consider only the simulated annealing algorithm and set fixed failure probabilities for each switch and each link. They observe that using too few or too many controllers reduces reliability. Simulations also show trade-offs between reliability and latencies in both topologies.

%\cite{HuWe13}: SDN networks have the control plane separated from the data plane, this split presents reliability problems, the gap between the control layer and the data capacity results in the loss of packets.
%Faced with this problem, given a failure of each component of the network, for example, controllers, forwarding devices or links. [Yannan Hu] et. at propose to determine how many controllers and how to connect them to optimize the reliability of the network?
%For this, the authors introduced a section called “Expected percentage of control path loss",  it is the number of break routes of control due to line failures, on this spot the controller-forwarding devices and inter-controller routes are defined, considering the latency between them.
%It is evaluated with several algorithms such as simulated annealing in OS3E topology. The results present the solutions are close to optimal and that the number of controllers to be located must be correct. Also that many or few controllers, reduce the reliability of the network.[USTA]


%\cite{HuWa12}: In an SDN network, the controller's location strategies influence the network, from node to controller latencies, to network performance.

%For this reason, it is important to generate an algorithm that provides an optimal location of the controller. The objective of this article is to provide an optimal location of the controllers if one takes into account that there is a network with a finite number of controllers.

%The reliability is considered a metric because if the links between the forwarding devices and the controllers fail, the control and data forward planes will be decoupled.

%An algorithm "Greedy" of random placement was chosen, this algorithm locates the controllers in the network in an iterative way in different places of the network, first it makes a list of possible places and calculates the lowest cost to each possible location, in the second iteration, takes a controller with the routes that converge to it and takes the least route in time, this process repeats it with all the controllers. The algorithm was evaluated in a topology of the Internet2 OS3E network and Rocketfuel topologies. The results displayed very well chosen and reliable controller locations for the network.[USTA]


\cite{LiLi16}: Liu et al. investigate the CPP by optimizing the average reliability between controllers and switches, assuming that the shortest path between two nodes is selected among all the paths. The authors propose two algorithms to solve the studied problem viewed as a clustering analysis problem. Firstly, they use the K-means algorithm to find the global optimal solution. However, the complexity of the algorithm being huge, they propose a greedy-based algorithm performing a sub-optimal solution with less computation complexity. In a second time, the authors consider the classic scenario where multiple paths are available between nodes, and not only the shortest ones. They introduce a reliability factor based on the number of paths between two nodes, the average path length, and the average correlation between links. Accordingly, they adapt their proposed algorithms to solve the relaibility-aware CPP. The performance is evaluated on the Internet2 OS3E topology and other topologies from the Topology Zoo, while no comparison with other algorithms in the literature is presented. In both scenarios, the authors ignore the switch‐to‐controller latency, inter‐controller latency and the controller load.

\cite{LiLi16}:The location of the controller in SDN networks is a major problem, because the network delay and synchronization will be affected, it is sought to improve the reliability of the network, is considered the shorter path between the controller and the forwarding devices,  a global optimization algorithm mixed with a greedy optimization algorithm is used, the results of the simulation give evidence of a better performance of the algorithms proposed in OS3E and Internet Zoo topologies.[USTA]

\cite{LiLi16}:Liu et al. considered in previous studies did not consider reliability to solve the CPP, indicating that it is a very important metric, since a failure of connection between a switch and a controller, affect flows later, considering that a switch you will not receive instructions. That is why proposed an algorithm to optimize network performance. First they studied the optimization problem based on the assumption the shortest route between the controller and the switches proposing two algorithms: Global optimization algorithm and Greedy algorithm. The algorithm first searches for a global optimal solution, but the computational complexity of the algorithms is huge. Therefore, to simplify the complexity of the calculation, They proposed a sub-optimal algorithm based on the greedy algorithm for driver location. In each iteration, the algorithm can ensure that local optimal solution is reached. They then expanded the optimization problem to the case of multiple paths between the controller and switches, however processing times are high, to fix this, they defined a reliability factor used to denote the reliability of the network. The authors state that the reliability can be represented by a combination of paths between two nodes, an average path length and the maximum link occupancy. However, using the maximum occupancy of the link for all paths between two nodes to indicate the reliability is not enough. For this paper, the authors assumed that each node is completely reliable to simplify the complexity of processing further based on the reliability factor, used the Bren dataset and topology Topology Zoo, assuming that were 6 drivers. Both algorithms are not affected by the number of controllers. This is because the reliability of multiple paths between two nodes is affected by many factors, including: the number of routes, route mapping, etc., and the length of the route is only one factor.[USTA]


\section{Cost}
\subsection{Definition}
In general, we use the term 'cost' to mean the deployment cost (CAPEX and OPEX). 

%In various papers, the authors meant by cost the workload of the controller. This definition is well pointed out when these papers are considered. 


\subsection{Papers}
\cite{SaSt15}: The objective of this work is to minimize the deployment cost subject to various constraints, such as the capacity and the flow-setup latency, which includes transmission, propagation and processing delays. The capacity includes the maximum number of packets sent by the switches the controller can process and the bandwidth that can be handled by the links between switches and controllers. The maximum number of connected switches and controllers to one controller is also maximized by the number of ports on that controller. The minimized cost includes the cost of installing a controller, the cost of linking controllers to the switches, and the cost for linking controllers together. The problem is formulated as a linear programming model and solved with the CPLEX optimizer. The authors observe a slight decrease in the deployment cost when the number of potential placement locations increases. However, only small size problems can be optimized within a reasonable amount of time with the proposed NP-hard problem resolution. 

\cite{SaSt15}:Sallahi et. to propose a mathematical model for the problem of the location of the driver software defined networks (SDN), in order to minimize the cost of the system, taking into account various constraints such as capacity controllers, latency settings the route, among others. Whether the SDN contains one or more controllers, the location of the drivers will have an impact on performance and cost of the network. The model simultaneously determines the optimal number, location and type of drivers, and all the interconnections between network elements.
to formulate the mathematical model, the authors assume that the following information is known: i) The location of all the switches in the network and the amount of traffic that must go to the controller from each switch. ii) The length and available bandwidth of each type of link to connect switches and controllers. iii) The characteristics of the different types of drivers. Each type of controller has a cost (money), a number of physical ports available, a maximum number of requests that can handle per second and the number of each type available drivers. iv) The maximum latency permitted for communication between the switch and the controller link.
The cost of network planning includes the cost of installing the drivers, the cost of connecting the controllers to the switches and the cost of connecting controllers to each other, which must be minimized.
To evaluate the model, a full mesh topology with 27 different sizes are considered. The number of switches is varied between 10, 20, 30, 40, 50, 75, 100, 150 and 200; the number of possible locations to install the drivers varied between 10, 15 and 20. These 27 combinations are generated in an area of 1km x 1km and allowed to see how they are affected time and cost optimization model. The simulation results showed that only small problems can be optimized in a reasonable time. In fact, approximately 10 percent of the problems can not be resolved within 30 hours. For performance, an option could be to derive approximate algorithms.
[USTA]

\cite{RaRe14}: The minimum number of controllers required in a network is calculated taking into account the number of flows and the average load that can be handled by one controller. Since the load can have dynamic changes, the goal of this paper is to dynamically calculate the optimal number of controllers needed for a topology, and to optimally map the controllers. The authors propose an algorithm of controller placement based on the games of theory that involve computational heuristics applied in artificial neural networks. The objective function being a non-linear function of the number of controllers and the cost (capital and operational costs), subject to both utilization (processor or memory or flow) and delay (processing and path) constraints. This algorithm is implemented in Matlab with a random network of 28 switches, assuming traffic arrival at those switches to follow Poisson distribution.

%The number of flows and the average load that can be handled by one controller are also taken into consideration. Since the load can have dynamic changes, the goal of this paper is to dynamically calculate the optimal number of controllers and map the switches to controllers while reducing the average switch-to-controller latency and balancing the load among controllers. The authors propose a non-zero-sum game based algorithm to solve the presented CPP. The authors also describe two algorithms to dynamically assign the switches to controllers in the cases of under or over utilization of controllers. In the former case, the controller  %The objective function being a non-linear function of the number of controllers and the cost (capital and operational costs), subject to both utilization (processor or memory or flow) and delay (processing and path) constraints. The authors consider that every controller can run either in master or in slave mode and that each switch must have at least one master and one slave controller. As the load on the network varies, one or new controllers can be added to handle the overload, or deleted in the opposite case, resulting in change of active controllers' placements and states (master/slave). 


%\cite{RaRe14}: The minimum number of controllers required in a network is calculated taking into account the number of flows and the average load that can be handled by one controller. Since the load can have dynamic changes, the goal of this paper is to dynamically calculate the optimal number of controllers needed for a topology, and to optimally map the controllers. The authors formulate the process to add or delete controllers to or from the network according to load changes as a distributed individual optimization problem. The objective function being a non-linear function of the number of controllers and the cost (capital and operational costs), subject to both utilization (processor or memory or flow) and delay (processing and path) constraints. A solution using a non-zero-sum game is proposed. After an initialization by placing one controller initially, controllers are added or deleted later on as required based on real-time changes in traffic. The authors consider a random network of 28 switches, assumed traffic arrival at those switches to follow Poisson distribution, and implement the proposed algorithms on each controller. 

%\cite{RaRe14}:In SDN, the controllers can work as virtual machines. In small networks the controller can be assigned in a fixed manner, however, in places such as datacenters, where the size and network load is constantly increasing, it is necessary to assign controllers to the forwarding devices dynamically.
%The authors [Hemant Kumar Rath] et al, propose in an algorithm of placement of the controller based on the games of theory that involve computational heuristics applied in artificial neural networks. This algorithm was implemented in Matlab and the latencies between forwarding devices and controller were considered, as well as the load balance in the controllers. Simulated in a random network of 28 forwarding devices. The results displayed homogeneous load in the controllers, efficient use of the controllers to their maximum capacity and reduction of the latency between forwarding devices and controller.[USTA]

\cite{RoRu14}: Despite to connect each node to several controllers, it is advisable to limit the number of controllers per node as well as the overall number of controllers in order to minimize the synchronization overhead between controllers  along with the deployment cost in a network. In this paper, the authors introduce the 'fault tolerant controller placement problem' minimizing the sum of costs of deploying controllers and serving switches, subject to a reliability constraint. An Heuristic algorithm is proposed and questions about the number of controllers to deploy, their placements, the nodes to which they must be assigned to are explored for different topologies. Simulation results show that the answers are dependant on the network topology more than to the network size. They also indicate that each node is required to connect to just 2 or 3 controllers to provide more than five nines reliability.

%\cite{RoRu14}: The authors introduce the 'fault tolerant controller placement problem'. They aim to find out the controller placement that minimizes the number of controllers and the costs of deploying the controllers and serving switches, subject to a reliability lower bound constraint (five nines). An Heuristic algorithm is proposed and questions about the number of controllers to deploy, their placements, the nodes to which they must be assigned to are explored for different topologies. Simulation results show that the answers are dependant on the topologies. They also indicate that a non-reliable network, i.e. without redundant paths, requires many more controllers than a redundant network of similar size. 

This work was extended in \cite{RoRu16}. The authors change their way to decorate the graph while solving the optimization problem, and thus get to find all disjoint paths that contribute to network reliability. This result leads to fewer controllers in the topology and fewer connections between controllers and switches. The authors also evaluated their proposition by analyzing the controller load, other reliability levels, and the runtime of the heuristic algorithm. The new results point out that, regardless the topology, each node only needs to establish a connection with two controllers at maximum to achieve more than five nine reliability level, which outperforms the results in \cite{RoRu14} where some nodes require three connections. 

%We note that in-band control was assumed in both of the papers.


\cite{RoRu14}:Ros et. al proposed a heuristic algorithm called FTCP (Fault Tolerant Controller Placement), which was focused on building solutions that meet reliability constraints while trying to minimize the number of controllers per node along with the total number of drivers. The goal of this optimization problem is to find the driver location directly minimizes the associated costs. Each controller has an inherited Capex and Opex cost of all this considering that each node must comply with a restriction of reliability, because an arbitrary location of the driver will not provide satisfactory performance. For this work, the authors took into account the so-called Internet network topologies Topology Zoo, in which discarded all the disconnected topologies; ie no point of presence, obtaining 124 topologies available PoP (Point-of-Presence). The authors found that the number of drivers required for high reliability southbound depends on the network topology. Unreliable network, ie a network without redundant paths, requires many more drivers that a redundant network of similar size. The authors suggest that for many networks require a reasonable number of drivers to achieve five-nines reliability. While the answers depend on the topology itself, many networks require a reasonable number of drivers to achieve five-nines reliability. [USTA]

\cite{BaRo13}: In this paper, the authors propose a framework for dynamically adapting the number of controllers and their locations according to network dynamics, while ensuring minimal processing delay and communication overhead at the controller due to synchronization and management workload. For this purpose, they investigate an optimization problem minimizing the total cost (statistics collection, flow setup, synchronization between controllers, and switch reassignment costs) subject to latency between a switch and its assigned controller and controller capacity constraints. The problem is formulated as an Integer Linear Program and two heuristics programmed in Python are proposed to find the optimal switch to controller assignment. The first one is a greedy approach based on knapsack problem, while the other is based on simulated annealing.  Both RF-I  (79 nodes, 294 links) and RF-II (108 nodes, 306 links) topologies are simulated and the inter-node latencies were obtained from the RocketFuel repository. The simulated annealing algorithm outperforms the greedy approach in both number of controllers and flow setup time, but it requires much more time to run. Both approaches succeed to find a right trade-off between flow setup time (processing time - the extreme case is when we have only one controller to all switches) and communication overhead (communication between controllers - the extreme case is when we have one controller to each switch). 

\cite{BaRo13}:The authors propose a management framework to dynamically provision multiple controllers and overcome the limitations related to performance and scalability that has centralized approach WAN topologies drivers. Dynamic provisioning controller modifies the number of drivers and their locations as traffic patterns on the network to minimize setup time flow (latency switch-controller to flow from end to end) and overhead (synchronization and management controller). For this a controller to a subset of switches depending on the fluctuations of the network is delegated. The authors make the problem of optimum dynamic provisioning controller as a ILP and use two heuristics to resolve in order to minimize the costs of collection switching states, inter-controller and reassigning switch to controller synchronization. Methods were evaluated by simulating two RF-I (79 nodes, 294 links) and RF-II (108 nodes, 306 links). The results show With the work developed achieved a balance between flow setup time and overhead, absent balance in SDN networks not had one or more static controllers. Methods were evaluated by simulating two RF-I (79 nodes, 294 links) and RF-II (108 nodes, 306 links). The results show With the work developed achieved a balance between flow setup time and overhead, absent balance in SDN networks not had one or more static controllers. Methods were evaluated by simulating two RF-I (79 nodes, 294 links) and RF-II (108 nodes, 306 links). The results show With the work developed achieved a balance between flow setup time and overhead, absent balance in SDN networks not had one or more static controllers.[USTA]

%\cite{BaRo13}: In this paper, the authors propose a framework for dynamically adapting the number of controllers and their locations according to network dynamics, while ensuring minimal flow setup time (processing delay) and communication overhead (synchronization and management). For this purpose, they investigate an optimization problem minimizing the total cost (statistics collection, flow setup, synchronization between controllers, and switch reassignment costs) subject to latency between a switch and its assigned controller and controller capacity constraints. The problem is formulated as an Integer Linear Program and two heuristics are proposed to find the optimal switch to controller assignment. The first one is a greedy approach based on knapsack problem, while the other is based on simulated annealing. Performance evaluation is checked out using an in-house simulator, due to some limitations of Mininet in the studied conditions. Both RF-I and RF-II topologies are simulated and the inter-node latencies were obtained from the RocketFuel repository. The simulated annealing algorithm outperforms the greedy approach in both number of controllers and flow setup time, but it requires much more time to run. Both approaches succeed to find a right trade-off between flow setup time (processing time - the extreme case is when we have only one controller to all switches) and communication overhead (communication between controllers - the extreme case is when we have one controller to each switch). 

%\cite{BaRo13}:The vast majority of the studies carried out regarding the CPP in SDN networks consider static values of a network, (i.e. the latencies between nodes never change). The first study that considered  dynamic provisioning for the CPP in SDN was proposed by [ D. Hock] et. al.

%SDN networks, in a large-scale implementation, the CPP is based only on a moment of the state of the network. This has limitations like a performance and scalability, for this reason, it is necessary to locate more than one controller in the network.
 
%However, there is a problem called "Dynamic Controller Provisioning Problem (DCPP)", which consists of dynamically adapting the number of controllers and their locations with the constant network changes. DCPP dynamically adjusts the number of active controllers and distributes them to several forwarding devices.
 
%To make these dynamic adjustments, two heuristic algorithms programmed in Python were used, the first was the DCP-Gk that uses the greedy knapsack problem and the DCP-SA that is based on simulated annealing. It was simulated in RF-I topology (79 nodes, 294 links) and RF-II (108 nodes, 306 links).

%The results show the decrease of the communication overload and the flow configuration time. The flow configuration is the installation of a new route in the controller proposed by forwarding devices.[USTA]


%\subsubsection{Definition of controller capacity}
%The idea is to optimally place the controller such that its load should not exceed its capacity. The controller load is mainly formed by the events processing (processing the PACKET\_IN events and delivering the events to the applications), the communication with other controllers, the installation of flow entries, the maintenance of a global view of the network, etc...



\cite{ChWa15}: In this paper, the authors introduce the QoS-guaranteed controller placement problem. They consider the minimization of the number of controllers in a topology, subject to the response time constraint. The response time of a controller consists of the round trip latency between the controller and a switch, and the service time of a controller which depends on the capacity and the workload of a controller. The authors compare three heuristic algorithms for various topologies form the Internet Topology Zoo: Incremental greedy algorithm, primal-dual-based algorithm, and network-partition-based algorithm. They demonstrate that the incremental greedy method slightly outperforms the other two methods.

The incremental greedy algorithm selects first the controller which can serve the maximum number of switches. At each iteration, the switch with the minimal delay from the controller is assigned to it. This operation is repeated until the average response time of all switches reach the response time constraint. However, this algorithm does not have any theoretical performance guarantee to the generated results. 

In the second method, the problem is formulated into an integer program. The primal-dual method then finds the near optimal solution to the integer program by using linear relaxation and the duality of the original problem. 

However, the above algorithms do no have a global view of the whole network, and they create unbalanced placement between controllers. The authors then detail the network-partition-based algorithm, which divided the network into partitions in a way that the maximum delay between two switches is within the response time constraint. In each partition, the incremental greedy method is used to place the controller.

\cite{ChWa15}:Yingying et al. proposed QoS - Guaranteed Controller to solve the problem of driver location, based on three heuristic algorithms: Greedy Incremental Algorithm, Primal - Dual - based Algorithm and network - Partition - Based Algorithm. Incremental Greedy, iteratively opens the driver, in this case the candidate who can attend as many switches until all switches are distributed. Otherwise, the algorithm Primal - Dual is a method for solving the driver location where you start with a feasible solution for two types of programs: one primitive and the other derived from the original; called dual. Where the original solution is used to determine the improved dual solution and vice versa. The interaction of this algorithm terminates when the original solution satisfies all slack conditions given at the beginning of the execution of the algorithm. Finally the Network Partition, is advantageous over the two previously mentioned algorithms, because this is a global view of the network. The basic idea of this algorithm is to divide the network into parts and placing a controller in each partition. These algorithms were tested on the network Topology Zoo, in which discarded all disconnected topologies, yielding strong results for the three proposed algorithms different values defining the propagation delay. The authors note that previous work has not been guaranteed an important parameter, as is the QoS, as it is the main concern of network operators,[USTA]

\subsection{Load balancing}
%When multiple controllers are employed for a topology, if the switches are assigned to their nearest controller using latency as metric, the number of switches per controller will be imbalanced. Thus, load balancing between controllers becomes an important criterion to consider, in order to prevent controller overload.

\cite{LiWa15}: In this paper, the authors propose a network clustering particle swarm algorithm to optimally locate the controller, taking into consideration the propagation latency, the load of controllers and load balancing. The controller load in this paper means the power rating of the controller. The idea is to combine the capacitated k-center, with the aid of a clustering algorithm, with Particle Swarm Optimization (PSO) which was used in \cite{GaWa15}. The proposed algorithm is compared with the k-center and the capacitated k-center algorithms. Simulation results show that the proposed algorithm can reduce the number of controllers when every controller avoid overload. Moreover, the proposed strategy presents a better control plane utilization than the other algorithms, along with better load balancing. The propagation delay obtained by the proposed algorithm is too close from the one obtained by the k-center algorithm. 


\section{Multiple-objective optimization problems}
In this section, we present various papers optimizing a multi-objective function to resolve the CPP.
%\subsection{Latencies, load balancing and resilience}
%\subsubsection{Load balancing}



%"When several performance and resilience metrics are considered, there is usually no single best controller placement solution, but a trade-off between these metrics."

%"We show that in most topologies, where a single controller would be enough from a latency point-of-view, many more controllers are necessary to meet resilience requirements."

\subsection{Papers}

\cite{HoHa13}: Most of the SDN literature dedicated to the location of the controller, presenting the problem of location as "NP-Hard", the solutions to this problem display high CPU processing times, memory expenditure and processing time.
In this paper, an exhaustive evaluation of multiple metrics is presented and the resilient Pareto-based Optimal Controller placement (POCO) is introduced. The proposed framework allows to investigate a multi-objective optimization problem, offering all possible solutions evaluated by all objectives, allowing to select afterwards the placement that is most adequate for each one needs. The optimization objectives addressed by the authors are latency between nodes and controllers, inter-controller latency, load balancing between controllers and resilience. For resilience, the authors consider both tolerance on network disruption as well as controller failures. Analysis are applied mainly on the Internet2 OS3E topology, along with other topologies from the Internet Zoo Topology to validate the results. Simulations evince an improvement in calculation times, a more efficient use of memory and RAM.

%\cite{HoHa13}: In this paper, a framework for resilient Pareto-based optimal controller placement (POCO) is introduced. The proposed framework allows to investigate a multi-objective optimization problem, offering all possible solutions evaluated by all objectives, allowing to select afterwards the placement that is most adequate for each one needs. The optimization objectives addressed by the authors are latency between nodes and controllers, inter-controller latency, load balancing between controllers and resilience. For resilience, the authors consider both tolerance on network disruption as well as controller failures. Analysis are applied mainly on the Internet2 OS3E topology, along with other topologies from the Internet Zoo Topology to validate the results. The authors reveal that "in most of topologies, more than 20\% of all nodes need to be controllers to assure a continuous connection of all nodes to one of the controllers in any arbitrary double link or node failure scenario".

%\cite{HoHa13}:Most of the SDN literature dedicated to the location of the controller, presenting the problem of location as "NP-Hard", the solutions to this problem display high CPU processing times, memory expenditure and processing time. [David Hock] et. al propose an algorithm for resilient Pareto-based Optimal COntroller placement (POCO), which evaluates all possible solutions to the location of the controller taking into account the resilience and fault tolerance metrics, this method was evaluated in an OS3E topology internet2, the results evince an improvement in calculation times, a more efficient use of memory and RAM..[USTA]

\cite{HoHa14}: The authors extend their work in \cite{HoHa14} where they present the POCO-PLC method applied to the CPP in a dynamic way in SDN networks. Their proposal enables real-time performance analysis, using the PlanetLab network programmed in Python that measures the latency between external nodes and latency between local nodes in real time, as well as the load on the CPU. Then "Planet Lab" dynamically chooses the controller closest to the node in terms of the latency. Since the controller assignment is dynamic, it allows comparing in real time the different locations of the controller with respect to the previous locations.

%The authors extend their work in \cite{HoHa14} to integrate dynamics into the controller placement problem resolution. Their proposal enables real-time performance analysis, based on monitoring data, by the integration of the PlanetLab network. To this aim, they use a set of PlanetLab nodes as switches, and equip them with an agent to collect measurements of latencies and node loads. This allows to analyze different use cases based on dynamic measurements. 

%\cite{HoHa14}: In this approach, authors described the POCO-PLC method applied to the CPP in a dynamic way in SDN networks. Using the "Planet Lab" research network programmed in Python that measures the latency between external nodes and latency between local nodes in real time, as well as the load on the CPU. Then "Planet Lab" dynamically chooses the controller closest to the node in terms of the latency. Since the controller assignment is dynamic, it allows comparing in real time the different locations of the controller with respect to the previous locations.[USTA]


\cite{LaGe15}: POCO, in its default configuration, performs an exhaustive evaluation of all possible placements. Thus, it is practically possible only for small and medium sized networks and cannot be feasible for large-scale or dynamic networks as it has high time and resource constraints such as processing and memory. 
Consequently, the authors in \cite{LaGe15} propose an heuristic extension of POCO, that is less accurate but yields faster computation time. The authors derive guidelines for deciding whether to use an exhaustive evaluation or to switch to an heuristic approach, according to different use cases and requirements. The heuristic algorithm proposed in this work is based on Pareto Simulated Annealing (PSA), a Multiobjective Combinatorial Optimization (MOCO) algorithm inspired by simulated annealing. The heuristic method analyzes the trade-off between the time and accuracy and takes the latencies of the nodes, the latencies between the controllers, failure tolerance in nodes , failure tolerance in links and the load balance. The "Topology Zoo" was used to evaluate the performance of this proposal. Results showed that this method is less precise but faster to determine the location of the controller.

\cite{LaGe15}:Lange et. they proposed a heuristic algorithm Pareto Capacitated K - Medoids (PKCM) to solve the problem of driver location, combined ideas from different algorithms theoretical graph, and so build optimal approximation of Pareto Frontier considering two objectives average latency node controller and imbalance (imbalance) in the load controller. This algorithm is tested in actual Internet topologies Topology Zoo. In the first instance the location for the controller with minimum average latency between node is calculated - controller, respecting the imbalance (in this case the number of nodes assigned to a controller) by a first algorithm called Capacitated k-Medoids. 
Another algorithm then who is responsible for taking the result and make n iterations to shed runs possible solutions, allowing the better result. As part of the evaluation of algorithm, the results of time and effectiveness compared to a generic algorithm to optimize criteria arbitrarily as (PSA) Pareto Metaheuristic Simulated Annealing. The results show that using a specialized development for the problem of the location of the driver is more effective than a generic algorithm, due to its low computation time and acceptable margin of error. 
These conditions allow it to be used in automated decisions for systems operating in dynamic environments. As part of the evaluation of algorithm, the results of time and effectiveness compared to a generic algorithm to optimize criteria arbitrarily as (PSA) Pareto Metaheuristic Simulated Annealing. The results show that using a specialized development for the problem of the location of the driver is more effective than a generic algorithm, due to its low computation time and acceptable margin of error. These conditions allow it to be used in automated decisions for systems operating in dynamic environments. 
As part of the evaluation of ¹algorithm, the results of time and effectiveness compared to a generic algorithm to optimize criteria arbitrarily as (PSA) Pareto Metaheuristic Simulated Annealing. The results show that using a specialized development for the problem of the location of the driver is more effective than a generic algorithm, due to its low computation time and acceptable margin of error. These conditions allow it to be used in automated decisions for systems operating in dynamic environments. The results show that using a specialized development for the problem of the location of the driver is more effective than a generic algorithm, due to its low computation time and acceptable margin of error. 
These conditions allow it to be used in automated decisions for systems operating in dynamic environments. The results show that using a specialized development for the problem of the location of the driver is more effective than a generic algorithm, due to its low computation time and acceptable margin of error. These conditions allow it to be used in automated decisions for systems operating in dynamic environments. [USTA]

%\cite{LaGe15}: Since POCO, in its default configuration, performs an exhaustive evaluation of all possible placements, which is practically possible only for small and medium sized networks, this paper proposes an heuristic extension of POCO, that is less accurate but yields faster computation time. The authors derive guidelines for deciding whether to use an exhaustive evaluation or to switch to an heuristic approach, according to different use cases and requirements. The heuristic algorithm proposed in this work is based on Pareto Simulated Annealing (PSA), a Multiobjective Combinatorial Optimization (MOCO) algorithm inspired by simulated annealing. An evaluation involving more than 60 graphs from the Internet Zoo Topology is performed. All evaluations are carried out with the same set of five objectives, namely node to controller latency, inter-controller latency, and controller load balance. Both average and maximum values are optimized for latency measures. 

%\cite{LaGe15}:When discussing the location of the controller in an SDN network, one or more metrics are considered to determine the place of the controller. Since there are multiple optimization criteria that may compete with each other, (). there is no a single answer to the CPP but rather a set of answers that implies a trade-off. Given this, in Pareto Optimal Controller (POCO) which makes an exhaustive review of all possible controller locations. Although this method is feasible for small and medium networks, it is not for large-scale or dynamic networks as it has high time and resource constraints such as processing and memory. In this approach,  authors use POCO combined with the heuristic method simulated annealing. The heuristic method analyzes the trade-off between the time and accuracy and takes the latencies of the nodes, the latencies between the controllers, failure tolerance in nodes , failure tolerance in links and the load balance. The "Topology Zoo" was used to evaluate the performance of this proposal.. Results showed that this method is less precise but faster to determine the location of the controller.[USTA]


\cite{JaAh15}: This paper proposes another heuristic extension to POCO based on NSGA-II (Non-dominated Sorting Genetic Algorithm II)  mixed with Pareto Frontier. This genetic algorithm is normally used in discrete and continuous optimization problems and this model is applied to the controller location problem. Latency between switches and its assigned controllers, inter-controllers latency, as well as load balancing between controllers are considered. A Matlab simulation of the "Internet2 OS3E" topology is performed and the proposed algorithm is proved to be efficient for achieving a good approximation of the Pareto Optimal frontier considering these objectives. 

%\cite{JaAh15}: This paper proposes another heuristic extension to POCO based on the NSGA-II algorithm. Latency between switches and its assigned controllers, inter-controllers latency, as well as load balancing between controllers are considered. The proposed algorithm is proved to be efficient for achieving a good approximation of the Pareto Optimal frontier considering these objectives. 

%\cite{JaAh15}:The location of the controller has become a critical task in SDN networks, when trying to locate multiple controllers, each location affects the metrics, creating a conflict. For example, considering latency between controllers and these are located closer to each other, the latency metric from controller to node is affected, this metric problem is known as "Multiobjective Combinatorial Optimization Problem (MOCO)", which has been worked using the "Pareto frontier". This method is very effective in problems small and medium combinatorial, finding the location of the controller in a reasonable time, but in large-scale problems, this algorithm involves billions of solutions, which is translated into consumed memory and high processing times .
%For this case was used the second version of the NSGA-II (Non-dominated Sorting Genetic Algorithm II) mixed with Pareto Frontier. This genetic algorithm is normally used in discrete and continuous optimization problems and this model is taken to the controller location problem. A Matlab simulation of the "Internet2 OS3E" topology was performed, the NSGA-II found a diverse and accurate Pareto optimization approach and takes into account the latency between controllers, latency between controller and node, latency between nodes and load balancing. This NSGA-II algorithm was efficient to find the "Pareto Optimum" approximations. This research shows the advantages over exhaustive evaluation methods that are in charge of finding a solution in the whole space.[USTA]


\cite{VaMo18}: The authors propose a heuristic algorithm called Multi-Start Hybrid Non-dominated Sorting Genetic Algorithm (MHNSGA) to solve the multi-objective CPP. The proposed algorithm is an adaptation of an NSGA algorithm especially based on greedy initialization and multi-start mechanism. Controller to switch latency, inter-controllers latency, and load balancing between controllers are optimized. Both average and maximum values are considered for latencies. Compared to the framework POCO, the proposed algorithm is able to find near-optimal solutions with much less run time and memory and, unlike POCO, it can be applied to large-scale networks. However, for such large-scale instances, it is not possible to evaluate the accuracy obtained by any heuristic algorithm since we can not calculate the exact solution for the evaluated placements. For smaller network sizes, MHNSGA is compared to POCO over 40 graphs from the Internet Topology Zoo and it is shown to provide an efficient estimation and good convergence towards the real Pareto optimal set. Compared to other heuristics, namely PSA \cite{LaGe15} and PSO-CGLPP \cite{GaWa15}, MHNSGA converges faster and outperforms the two algorithms in most of the time.  

Although this unconstrained model considers many factors crucial to place SDN controllers, the authors emphasize a new variant of the problem taking into consideration the controller capacity and the switch load. The constrained problem being a Multi-objective capacity-aware controller placement problem (MOCCPP), they adapt MHNSGA to solve the constrained multi-objective optimization problem. A comparison of the proposed algorithm to the adaptation of PSA and  PSO-CGLPP for MOCCPP proves the efficiency and superiority of MHNSGA on the others schemes.

\cite{VaMo18}:V. Ahmadi et al emphasize that the proposed algorithms around literatures studied, attack the problem of CPP networking medium and low level, based on which algorithms optimal as LITTLE is not enough to handle changes dynamic in large-scale networks because it requires long runtime. As for the features such as scalability, resilience, delays in the communication control plane and the restrictions are independent of time. This paper presents a heuristic algorithm called Multi-Start Hybrid Non-dominated Sorting Genetic Algorithm (or MHNSGA) to solve the problem location multiobjective controller effectively. In the context of multi-objective optimization, in most cases, a unique solution that optimizes all objectives can not be considered. For this work, the authors emphasized the following metrics: the latency between controllers, node (switch) or link failure and load balancing controller. These objectives can conflict with each other and, therefore, an appropriate approach is required to find a good tradeoff between them. Compared to the framework POCO, the proposed algorithm is able to find near-optimal solutions with much less run time and memory. In particular, MHNSGA can get high quality solutions for large-scale networks, while the POCO framework fails due to memory shortage. Although this model considers many factors crucial to implement SDN controllers, They should also consider other important factors. These factors include the capabilities of the controllers and switches loads. For this, the authors a new variant of the problem in which considering the capabilities of drivers and loads of switches, introducing a new algorithm Multi-objective capacity-aware controller placement problem (MOCCPP), addition latency spread between controllers, charge controllers is a critical factor in real networks. Given the limitations of the holder, the access bandwidth, memory and other resources, only a limited number of routers can be managed by a core server due to capacity constraints. In this model constrained optimization, More realistic assumptions were made compared to the original problem of driver location. Restrictions at MOCCPP were related to the capabilities of the controllers and switches loads. MHNSGA was adapted to solve MOCCPP by introducing a new management technique restrictions. These algorithms were tested under the Topology dataset Zoo, showed that the algorithms proposed here outperformed other efficient algorithms literature.[USTA]




%\subsection{Cost and Latency}
%The cost here stands for the controller workload.




\subsection{Weighted routing cost}

\cite{YaHo15}: The work presented in this paper encompasses two steps. In a first step, the controller placement problem is investigated for a single domain, i.e. where only one controller exists. In this case, the routing cost from switch to controller, the deployment cost, as well as the weight of switch nodes are considered simultaneously. The routing cost adopted in the study is the hop count. The weight of switch node being an index to its importance in the network and the maximum throughput it can achieve. Thus, the criterion can be seen as a weighted routing cost. The controller placement problem is investigated for a single domain network containing 16 nodes.

However, the assignment of a controller between the switches in a static manner generates load imbalance in dynamic flow conditions. Consequently, the authors propose, in the second step, a dynamic switch migration algorithm for multiple SDN domains, in order to adapt to the flow dynamics and realize load balancing between controllers. To this aim, the network topology is firstly divided into several sub-domains with a single controller in each domain. The number of partitioned sub-domains is determined according to the capacity of the controller and the requests of each switch. Finally, a dynamic scheduling strategy is proposed to release the overload problem and realize the load balancing between controllers. More specifically, when a controller becomes overload, it can cooperate with its neighbor controller and migrate the boundary switches to the neighbor domain to reduce its own load. The performance of the proposed algorithm is evaluated in the NSFNET topology, composed of two domains. Simulation results show better load distribution at times of network congestion.

%\cite{YaHo15}:The works developed in SDN show promising scenarios improving communication networks, however, the assignment of a controller between the switches contemplates static scenarios, which generates load imbalance in dynamic flow conditions. Long Yao [et al] in propose a switch migration algorithm, which migrates the load of the switches to other controllers when bursts of flow are detected. This algorithm was tested on an NSFNET topology and considered the weight of the switches and the switch-to-controller delay; the results showed better load distribution at times of network congestion.[USTA]

\section{QoS}
\subsection{QoS}
QoS stands for the response time of a controller, which consists of the round trip latency between the controller and a switch, and the service time of a controller which depends on the capacity and the workload of a controller.

\subsection{Papers}

\cite{HoGe14}: It is important to consider controller failures if the main controller fails, the nodes should look for another controller, which means that the network will have new latencies associated with the new assigned controller. Losing the main controller may mean that some nodes can not connect to another controller, so several metrics must be taken into account to find a good location for the new controller.

It has been shown that it is not enough to consider the latency metric between node and controller, other metrics must also be taken into account. This work< [1] shows in addition to the latency between node and controller, other metrics such as resilience, load balancing, and inter-controller latency. Matlab was used, taking "Topology Zoo". The algorithm uses the Pareto optimal and allows to compare the different locations of the controller according to the metrics taken into account. The result was the option to select several controller locations according to a particular metric.[USTA]

\section{Not classified}

\cite{SoXi17}: This paper does not treat the CPP but introduces the 'Controller Selection Problem' (CSP) which consists in dynamic addition or deletion of virtual machine based controllers based on the traffic demand and performance requirements. The authors firstly present different analysis to prove the influence of service rate and packet sending rate of switches on the performance of the controller, the affect of controller's capacity on the QoS requirements, and the impact of deploying additional resources or controllers in the network on the probability of flows in the queue. Afterwards, they propose a framework to decide which controller will serve each flow according to its QoS requirements (just theoretical explanation without model description or simulations). 

%\cite{SoXi17}: This papers introduces the 'Controller Selection Problem'. The authors believe that dynamic addition and deletion of controllers is inevitable in dynamic SDN environment. They show by simulations that the controller performance changes with the variations of number of switches and their rate. Moreover, they prove that the controller's capacity affects the QoS requirements. Consequently, the authors proposed to transform the controller placement problem into a controller selection problem.

%\cite{SoXi17}:Keshav et al. they identified three important points from his research: i) The underlying topology is not defined and is always dynamic. II) The traffic behavior and size change frequently. iii) Instead of analyzing the controller's ability, researchers must analyze the responsiveness of the controller, which is the main factor determining delay from end to end. Based on these points listed above, the authors propose changing CPP (Controller Placement Problem) CSP (Controller Selection Problem), exploring the relationship between traffic intensity, resource requirements and QoS requirements. Proponents showed that the charge level and the response time of a driver, It affects the performance of the same driver when the flow pattern is performed re-actively. They also proposed an independent topology to optimize the control layer in order to calculate the optimal number of drivers and reduce the workload and investigate the location of the driver. Also, note that no single solution is best for all cases.[USTA]


\cite{TaAl17}: [Erika Tarazona] et al, they elaborate a study of the most known techniques on the placement of the driver in SDN.
For heuristic methods propose with "Pareto Optimal Controller", the location of controllers in a large scale network in SDN.
Another research by Francisco J Ros, shows the performance challenges facing an SDN network when there are changes in the network. The results of this study showed the reduction of the number of controllers and improvement in reliability.
Another work, by Stanislav Lange, who proposes a heuristic algorithm to give a compensation between calculation time and controller precision.
It is necessary to optimize multiple objectives at the same time, that's why the multicriteria is used, this multicriteria must be feasible in calculation and optimization. For this reason, heuristic methods are used that allow precise solutions to be made in terms of time in large-scale topologies.[USTA]


\cite{FaXi18}: Most research on the CPP did not contemplate the reliability of the communication or the latency between the controllers in the case of the failure of a link.[Yuqi Fan] et. al and others, they took the communication time between the forwarding devices and the controller, taking into consideration the failure of a single link.
In this case, an algorithm called "Latency-Aware Reliable Controller Placement (LARC)" was designed that looks for the shortest path in time, between controller and forwarding devices. The ATT (North America) and Internet 2 topologies were used.
The results display a lower latency in the main links and backup links between the controllers and the forwarding devices when the link that connects these devices fails.[USTA]

\cite{BlBa15}: Blenk et al. initiated the study of HPP (Hypervisor Placement Problem), considering virtualizing network (NV), adding new dimensions to the CPP and is seen as a key to enable the improvement of network resources communication, adding to this the benefit of programmability and flexibility of real-time network that provides SDN; allowing provide means for dynamically flexible interconnect network functions in real time. Some authors suggest that a network SDN not virtualized, the controller performance and design of the control plane may have an impact on the network performance, such as latency. For this paper, the authors propose the first mathematical model for HPP, SDN given topology with the possibility of allocating the hypervisor and a number of vSDN. The authors propose 4 metric based on Average and Maximum Latency: Maximum (Worst Case) Average Latency, Average - Maximum Latency and Maximum - Average Latency. The topology was chosen for testing ATT North America, Topolology Zoo dataset, which consists of 25 nodes, showing that there is a dominant location for the hypervisor under different objectives; that is, when average-maximum and maximum-average targets are considered more nodes provide an optimal solution for the location of the hypervisor. A good location hypervisor is essential for designing SDN virtual networks because it affects latency control plane of vSDN.[USTA]

\cite{SaSa17}:Sahoo et. al, proposed solutions for solving two metaheuristic CPP. In This approach, authors presents two population-based meta-heuristic algorithm: Particle Swarm Optimization (PSO) and Firefly. The PSO approach into account Takes two types of learning (ie social and cognitive), while the Firefly approach considers the bio-Luminescence biochemical process. Authors use controller to switch latency and inter-controller latency as the optimization metrics. The latency refers to the time spent by a packet from the source node to the destination node, given that in SDN, latency propagation between the node and the controller is proportional to the distance between a node controller. The goal of This work was to find the optimal number of controllers and Their location. Theses Were tested by using algorithms TataNId the network topology from the Topology Zoo. This topology Consists of 144 nodes and 141 edges. Results show Firefly That approach is better than PSO in terms of average and worst-case latency and it converges slightly faster than PSO.[USTA]


\cite{AhJa15}:Vahid et. al proposed a heuristic algorithm called Hybrid NSGA - II, which demonstrated the efficiency when require high computational effort and processing time during the test. The algorithm has good performance also in cases where the network needs to adapt to changes, and even efficient large-scale networks. Find an optimal location of the driver introduces different challenges to make a decision; ie it can be influenced by many crucial respects. That is why this work focused on the location of the driver taking into account the following metrics: latency between node - driver, driver - driver and load imbalance.The last column of the table corresponds to the solution by Hybrid algorithm NSGA - II, one can see that is at least 50 percent of the possible solutions, speaking in less time resources machine and run time.[USTA]


\cite{JiCe14}:Jimenez et al. improved and evaluated algorithms proposed above with K-Critical, algorithm tasked with finding the minimum number of drivers and their location, in order to create a topology robust control dealing with robustness failures and load balancing belonging the selected drivers, please communication between controllers and nodes, such as delay, latency, convergence time, etc. The authors proposed the following objectives parameters scalability, strength and balance, seeing it from the perspective of the CPP. This algorithm was tested on a software called Gephi is an open source software for graphics and networking code analysis, this software can simulate large networks in real time and to accelerate 3D exploration. The authors showed that the number of selected drivers, and its location determines the performance of the network. It can also be inferred from the results obtained, a poor selection can greatly affect the robustness of the network and proportionally network operation such as: long recovery after failures. Otherwise, using more optimal controllers, it would become inefficient and costly, because the delay is negligible improvement. long recovery after failures. Otherwise, using more optimal controllers, it would become inefficient and costly, because the delay is negligible improvement. long recovery after failures. Otherwise, using more optimal controllers, it would become inefficient and costly, because the delay is negligible improvement.
The authors define scalability controller as: Ability to handle a certain number of flows per second and response time to events, such as updating information on drivers, responding to a request, etc. These not only depend on the ability of the drivers for the storage and processing.[USTA]


\cite{KsBa16}:Kasentini et al. they proposed three solutions for optimal location of the driver, among them are: i) CCA (CC communication overhead Aware solution), which helps reduce overhead between controllers, minimum and maximum applied. ii) SCA (SC Aware communication overhead solution) as its name implies, helps reduce overhead between switches and controllers. Usually this parameter is defined by the network operator, according to the link between bandwidth and traffic handled by different switches. iii) FTCS (Faire optimal Tradeoff Between C and CS communication overhead solution) which uses the theory Nash Bargaining game to ensure balancing between the two methods previously named CEC and SCA. Finally it is modeled through an optimization problem, where metrics are: Overloading SC, DC and communication system. These proposed solutions were tested using IBM CPLEX, Matlab and CVX 2.0, which concluded that the solution helps to jointly integrate the 3 objectives citrus: minimize latency, minimize overhead communication between CC and ensures load balancing, taking into account these objectives are somewhat contradictory, which helps to believe in the method.[USTA]


\cite{MaDu16}:Mattos et al. proposed a distributed control architecture, creating separate areas, wherein each controller is designated to each area, this architecture considers resilience driver while the driver location is performed. The authors proposed two heuristics to optimize the location of the driver based on minimizing the likelihood of network partitioning, FairMAx, PartMin, this second stage based on the fair distribution of switches controllers, ensuring network resiliency. Optimization criteria used for this work is i) minimize latency between controller and switches, ii) resilience. The prototype of the proposed controller was implemented in three topologies real networks: RNP (National Research Network) in Brazil with 30 nodes, GEANT network in Europe 40 Nodes and AT & T MPLS in the USA with 25 nodes, running random failures in the network nodes and verifies the ration of the network is connected and controlled, even after failure. The results of the two algorithms were compared with other algorithms such as Greedy, Centroid, Hops, PartMind, FairMax where the latter were the highest, since it is the only heuristic which considers load balancing between controllers, as a metric, taking into account the load balancing is performed by the switches exponentially weighted count above a controller as part of the metric. Furthermore, the authors showed that the global view of the network is maintained, even in a scenario where control is physically distributed.[USTA]


\cite{VoBo15}:Borcoci et al. constructed an analytical view of some proposed solutions in different literatures, together with an optimization method based on multicriteria decision (MCDA), applicable to the problem of driver location. The authors indicate that for optimal location of the driver, this can be achieved, trying to solve the following points: a) increased response times of forwarding nodes, due to the high number of switches assigned to a controller. b) interconnect and update or synchronize their databases. c) failure to the controller, network disconnection between the control plane and data. Additionally, they note that the purpose of the paper is not develop a specific algorithm to find an optimal solution for given criteria; otherwise, to achieve overall optimization of the driver location using multicriteria decision. In this case, proponents used some decision variables such as: Average Latency, worst latency (Failure free case), Intercontroller Latency, giving equal priority to each of them, and indicating that the network provider must apply two policies the correct location of the driver, giving priority to priority variables or metrics. The authors concluded that the method is generic enough to be applied in several stage and internet providers can include resolving the cpp in a specific network. [USTA]


\cite{HuWa14}:Yannan et al. studied the CPP, to maximize network reliability control SDN formulating algorithm called Reliability - Control aware placement problem. Proponents found that the number of drivers and their locations (along with the allocation ratio between switches and controllers) provides fundamental limitations on the reliability of networks SDN control. They also ensure that the location of the drivers, affects the reliability of the network, based on three assumptions: i) traffic control uses the connection existing between switches on the network. ii) No load balancing traffic control. iii) multiple controllers are connected in mesh. To find the most reliable driver location the authors proposed a metric that reflects the reliability of SDN networks, called Expected percentage loss of control path, where the path loss is defined as the number of routes of broken control due to network failures. Accordingly, the objective is to minimize this fault. The authors simulated based on real Topologies Topology Zoo experiment, assuming all nodes are able to accommodate drivers. They took their ISP Network Topology simulation obtained from ROCKETFUEL analyzing the location of the driver by two metrics: reliability and latency. The authors found that SA Algorithm, is closer to the optimal solution. Additionally, They found that optimizing reliability in different topologies, leads to results similar benefits. On the other hand, placing many or few drivers, reduces network reliability; Therefore, an optimum value for reliability and latency, are often impossible to achieve simultaneously. Finally proponents point out that the performance of location used directly dependent algorithm.[USTA]

\cite{HuWa14}:Y. Hu et al. address the problem of the location of the driver from the viewpoint of reliability (reliability). Propose a metric called expected percentage of loss of control path to measure the reliability and analyzes the flaws in the path-dependent control networks SDN control. Also prove that the driver location reliability is NP-hard and try different location algorithms analyzing the tradeoff between reliability and latency. While the choice of design can be affected by numerous factors, they found that the number of drivers and location put fundamental limits to the reliability of networks SDN control. Given a physical network and the probability of failure of each component of the network (e.g., links and switches), the authors determine how many controllers are needed and how to place so that a target reliability (reliability) preset is optimized. In this design option they called the problem of driver location reliability. In the metric proposed control paths are defined as the set of paths that are used for communications between switches and controllers and between the controllers themselves, in order to maximize reliability.
Topologies used to evaluate the results were Internet2 OS3E six Topologies topology ROCKETFUEL project. The authors' analysis is based on the assumption that each switch is only connected to a controller using a route. Within the results they mentioned that the performance of the placement depends on the specific algorithm used. Among the algorithms proposed in this document, the algorithm Simulated Annealing provides near optimal solutions. Furthermore, placing too many or too few controllers reduces reliability. Finally, the simulation results show tradeoffs between metrics. However, the latencies for the optimizing reliability are sufficient to meet the requirements of existing response time. [USTA]





\cite{MaJe18}:Martyna et al. proposed a method for optimizing reliability (reliability) to solve the problem multi-controllers location, ensuring reliability for deploying drivers in SDN. The optimization method proposed is a modification of the algorithm Greedy, in which a fault model is introduced to analyze the aspect of reliability, and evaluate the ability of the network to operate in the presence of faults (Fault - Tolerance), considering that not all components of SDN fail while operating. The algorithm was simulated in the dataset Internet Topology Zoo, taking topology Bren, a total of 37 nodes, which are taken into account three scenarios, comparing the result the effectiveness of the proposed HS method (Simulated Annealing ). In each iteration a new solution which is accepted if it has a lower cost to the result in the previous run is generated. As a result it was found that the average network failure decreases relative to the number of controllers for both the proposed method to SA.[USTA]



\cite{NgMi13}:k. Nguyen et al addressed the problem of CPP targeting a resilient network, emphasizing two problems: 1) communication between controllers and network devices. 2) Recovery of the network after a connection failure. The authors indicate that the physical separation of control plane and data plane, reduces the reliability of communication between the two planes. Therefore this is the main problem to be attacked in SDN. That is why we selected the propagation delay as the main parameter to investigate, since this affects network performance and resilience. Additionally, they note that the SND is another problem of dealing with changes of the network, for example in case of failures or configuration changes; which they are very common in disasters. For this job, the authors simulated a disaster resilient network with reference dataset topology topology zoo, SINET3. Which it is the largest national research and education network in Japan, considering each node as an element of SDN (controllers and network elements). On the other hand, the authors defined and evaluated two latency metrics: Average - Case and Worst Latency - Latency case. They then used the method called "Brute Force Method" to find the driver location, combining the two metrics listed above. They followed to obtain the optimal location of the drivers, simulated faults in software called POX, which simulated a similar disaster event that occurred in northern Japan in March 2011. At the time of submission of a link failure, The results confirmed the rapid restoration of TCP traffic in the SINET3 based on SDN / OpenFlow. The reception rate tends to decrease sharply, but recovers very fast as 10 and 30 seconds. This is because the driver has an overall view of the network, then forwarding rules filled the devices. Therefore, the traffic flow is easily converted to a new route. Failures do affect performance, but the recovery process was very fast. traffic flow easily becomes a new route. Failures do affect performance, but the recovery process was very fast. traffic flow easily becomes a new route. Failures do affect performance, but the recovery process was very fast.[USTA]


\cite{WoLi15}:W. Kim et al proposed a heuristic scheme (HES-CoP) switch location - SDN controller for distributed in DCN (Data centers Networks) drivers. The proposed algorithm consists CoP Hes-2 core elements in the orchestrator: a) responsible for decision making and 2) placement algorithm forward and backward SC. SC forward, initially choose the switch that contains the highest traffic load control in an SDN controller, and selects the switch SC backward experiencing lower traffic load control in an SDN controller first. Then it defined when to change the master functions for switches. HES-CoP tries to balance the traffic load control and reduce setup time flow, considering using OpenFlow OpenFlow protocol and switches, as OpenFlow is the de facto standard in the field SDN. Showing result, a distribution of the traffic load control is better than that used in other schemes. Therefore, HES-CoP is very suitable in DCN. The authors conclude that the proposed scheme is heuristic, not an optimal solution; as Hes-CoP is designed only for DCN, not for other environments, such as enterprise networks, campus networks and wide area networks (WAN). Finally, this scheme does not consider the amount of SDN efficient drivers needed to manage switches enumerable. In other words, HES-CoP uses fixed amount SDN controllers and can not generate new SDN controllers, when the number of switches increases exponentially. To evaluate the scheme experienced using the following two scenarios.[USTA]


\cite{FaSh17}:Farshin et al. indicate that software defined networks, are a very important part for cloud computing, because they help streamline the dynamic networks, this paper proposed a framework (management framework) for this architecture. Which it is to help reduce the cost of datacenter through the driver location. This method called Chaotic gray wolf optimization algorithm (GWO) is a metaheuristic algorithm based on the model of queuing network controllers, evaluated with real workloads, showing satisfactory results against QoS and future use for 5G technology.
The authors performed simulations with real workloads, where the results show that this approach will improve the computation time and the accuracy of the solutions, and better QoS performance and lower overall utilization in the cloud, as the size and rate of traffic from wireless and mobile networks are quite large, the use of traditional SDN (using only one SDN controller) is no longer practical. Since each controller has a rate constant service to connect too many switches will increase the flow setup time (ts). Consequently, you can not meet the requirements of QoS in networks. Therefore, to overcome this problem, the control plane should be distributed among several SDN controllers located in different regions of the network. In the distribution process control plane, the number of drivers also becomes important because it can directly affect operating expenses (OPEX) and capital expenditure (CAPEX) in the network and assign drivers statically can increase these costs. Therefore, you should also calculate the number of SDN controllers in the mobile network.
time flow configuration (ts) and the installation time of the rule (IRT), which can vary by changing the location of the drivers and application speed switches connected to each controller. The framework consists of several classes and each class has its own topology and switching drivers, we should use two nested Chaotic GWO. The first level will find the best number of drivers for each class and the second level will find the best connections and switch controller based on the level suggested by the first solution available. If the number of drivers used the best solution is less than the number generated by the first level of GWO, the changes are applied before executing the next iteration.[USTA]



\cite{LiYo16}:JM Sanneret al used the algorithm NSGA II, because in their extensive search around literature, is a revolutionary multi-objective, demonstrating good performance when evaluating objectives that conflict with one another; such as: Average Maximum Load Imbalance and connectivity. In addition, being multiobjective, this algorithm is able to evaluate up to three targets at once, which is why the authors focused on three metrics for development work such as: Reliability, latency Between Controllers and Switches and operational costs. This algorithm was tested under the Topology dataset Zoo, where the answer to the ILP solver compared, considering that this is for small networks instance. The authors say that thanks to the structure of the algorithm.[USTA]


\cite{ZhWu17}:Increased traffic on the WAN software defined networks (SD-WAN) requires a large number of drivers are considered and special attention to the criterion of scalability when dealing with the problem of driver location is set. In order to raise a scalable architecture, the authors propose to divide the network into several smaller sections, called SDN domains and locate them the least amount of controllers in each domain. Subsequently, group controllers in multiple sets called sets of controllers (SCs). Union logic controllers each domain functions as a single centralized controller. Each CS is composed of a main controller and several subordinates.
Considered metrics include delay CS-CS link, delay switch-CS, number of drivers and load balancing between SDN domains. ILP is used and a heuristic algorithm for the location of drivers distributed (DSP) With the aim of optimizing the delay links, network cost, related to scalability and performance cost function. Optimization mechanisms proposed were evaluated by simulation in a topology own authors with 11 nodes and 26 links. The results show that the heuristic approach can achieve suboptimum compared to the exact approximation.[USTA]


\cite{AlAy17}:Aloulou et. to explore the problem of driver location SDN networks to optimize Named Data Networks (Named Data Networking NDN) for the common deployment scheme of one or more controllers depending on performance requirements. Related challenges are addressed authors determine the optimal number of drivers capable of handling network traffic and find the optimal location of the drivers that minimizes driver load and latency inter-controller.
The problem addressed by dividing the network into domains and selecting a driver for each. the location of the driver as an integer linear program considering the tradeoff between two metrics was formulated: communication latency intra-domain, based on the average latency between a controller and switches assigned, and communication latency between domains, represented by average delay between neighboring controllers. Topologies used for performance evaluation were Internet2 and GÉANT. The results showed significant improvements in terms of latency in downloading data and average performance.[USTA]



\cite{HeBa17}:The location of the SDN controller must be adapted for dynamic traffic flows, otherwise, in order to minimize the settling time end-to-end flow. He et. They discuss resolution to this scenario simultaneously optimizing the location of the driver and the driver switch-allocation to minimize the average time of flow configuration respect to different traffic conditions in the network. The problem is formulated as a problem of nonlinear programming (NLP) with the objective of minimizing the average setup time given flow the flow profile as input, followed by linearization methods necessary to transform a MIP problem and solving of optimally. For this purpose they used the metric of average flow setup time.
The model was evaluated and tested in topologies Abilene (11 nodes) and AttMpls networks (24 nodes), taken from Topology Zoo. Resulted in a 50 percent reduction in the average setup time flow models driver location of the static location thereof was obtained.[USTA]



\cite{GoGi17}:Virtualization of the network has been proposed as critical to the future of the Internet item, which abstracts the network physical substrate. SDN enables virtualization of the network to share the SDN physical network among multiple virtual networks SDN (vSND) each with its own controller. Because resources are finite physical SDN is crucial to efficiently allocate vSDN applications, known as the problem of integration of VN into a network virtualization environment. Gong et al first considered the location of the driver and the integration of VN as a set of embedding vSDN problem. For this purpose a multiobjective ILP formulated and solved with a novel heuristic method which they called CO-vSDNE order to minimize the cost of embedding and the average delay for each controller-switch vSDN. As a result, the controller can communicate effectively with all switches in the same vSDN and makes efficient use of the resources of the SN. In formulating the algorithm considered i) delay, defined as the ratio between the total delay of the bond of the substrate through which the virtual control links and the number of virtual control links; ii) the cost for the total resources allocated to the VN substrate; and iii) acceptance ratio, defined as the ratio between the number of successful vSDN assignments and the total number of requests vSDN.
To evaluate the proposed algorithm Gong et al. used the GT-ITM tool to generate topologies SN requests vSDN. The delay end-point was measured by the "ping" and the throughput by transferring files TCP (transmission control protocol) with the IPREF tool. The results showed better performance in terms of average delay controller-switch, acceptance ratio, cost, and end-end throughput delay compared with two simple variations: DM-CM-vSDNE and vSDNE.[USTA]


\cite{VaPo17}:Vaishnavi MILP et al propose a model to allow provisioning virtual control plane in the same network to which it connects and controls, using inband control channels; while it is addressing the traditional requirements of the CPP. Virtualizing the controller, control paths between switch-controller depend on where the driver is located. Therefore, the switches must be assigned to controllers that allow the subsequent supply of the control path band between the switch and the controller. Thus, the proposal ensures that the band control path from a switch to a controller only pass through switches that are also assigned to the same controller.
They considered a scenario with a random physical substrate formed of switches that must be assigned to controllers and control elements candidates for locations. Switches and locations are connected to each other by bandwidth and delay (delay) known. The load switches generate controllers is also known, as well as the total load that can handle each virtual controller.
For evaluation topologies available were used in the TopologyZoo and Internet2 and confirmed that the proposed works to truly virtualized environments in an SDN infrastructure in which the control plane is embedded on the network to be controlled while procures control channels and solves the problem of deadlock. MILP extensible model can be used to design many objective functions, including those for switch failures, resilience and minimizing control elements.[USTA]



\cite{PeRe16}:Perrot et al. Formulate a ILP for the CPP with the main objective to minimize the number of active drivers that are needed in a WAN, considering several levels of backup controllers and maintaining latency, capacity constraints and load balancing. Considers the maximum allowable latency between switches and controllers, the maximum latency between controllers and restricting load balancing between controllers subdomains. Restricting maximum latency is introduced to ensure good performance .. all candidate nodes from which you can access a switch within the maximum latency required are calculated. With the formulation ensures that each switch is assigned to the nearest driver and all drivers have an equal number of switches to be managed. In addition the formulation vides various levels of drivers backup in case of failure of the primary drivers.
The proposal was evaluated in topologies issued by SND Lib. In the sensitivity analysis they found that when the probability of failure of drivers is close to 0, the formulation tends to give very little support levels. When the graphics are denser, more possible connections controller-switch and require fewer drivers. The optimal number of drivers depends on the length of the shortest average distance. The number of drivers increases as the maximum latency decreases[USTA]



\cite{HuLu17}:Hu et al. Address the CPP from the perspective of energy consumption in order to maximize energy savings network. To save power, the number of links used in the control network should be the lowest possible. To find the optimal solution sensitive to energy CPP, they formulated a binary integer program (BIP), minimizing the energy consumption of the network used to control traffic, together with the propagation delay and load drivers. Considering the high complexity of the problem in large-scale networks, called a genetic algorithm improved genetic algorithm controller placement (ICGPA) is introduced to find an optimal solution.
The proposal was evaluated in four topologies with different scales SND-lib, including Abilene (12 nodes, 15 links), Janos-us (26 nodes, 42 links), Pioro (40 nodes, 89 links) and Zib ( 54 nodes, 81 links). To examine the improvement in energy savings considering the energy consumption of the control network, compared the BIP and IGCPA methods with CCPP method that considers the problem of placement of trained driver, in order to minimize the maximum delay control paths taking into account the driver load. The results of the evaluation indicate that the IGCPA can find a near optimal solution. If all links have the same power consumption, less than 4 percent additional links are used by the genetic algorithm.[USTA]



\cite{AbMa17}:Abdel-Rahman et al. They studied the problem of the location of the driver when the link between the controller and the controlled element is wireless. They addressed the problem of the location and allocation of joint controllers with a deterministic model when delays are known link decisively and one stochastic for wireless links.
In the deterministic model they assumed cable connections between the controllers and the controlled elements. They made this problem considering two different QoS metrics. In the first formulation, they restricted the average response time of each controller (averaged over all nodes assigned to a given controller) to be less than a predetermined value. They expressed as a linear mixed integer program (MILP). In the second formulation, they restricted the maximum response time of each controller and expressed as a ILP (ILP). They then using stochastic programming constrained by chance (CCSP, for its acronym in English), they extended the formulation to the case where the links between the controllers and the controlled elements are wireless.
They evaluated deterministic schemes, using 16 network topologies. Stochastic scheme for the simulated two different sizes (nine sixteen nodes). The results demonstrated the advantage of the overall scheme in terms of reducing the required number of controllers compared to an allocation scheme and sequential location. They also showed the ability to meet CCSP based on probabilistically time constraints response scheme controllers.[USTA]


\cite{SuMa18}:To overcome the shortcomings of vehicular networks Vehicular Ad-hoc Network (VANET), such as poor dissemination of information, security vulnerabilities, inability to cope with changes in dynamic topology resulting in low levels of package delivery and high delays end to end; SDN concept applies in VANET, called Software Defined Network Vehicle (SDVN) and provided with flexibility and programmability along with improved performance. In VANET, vehicles will be equipped with on-board units (On Board Units, OBU) and unique stationary units Road (Road Side Units, RSU) are deployed in the network with the purpose of disseminating important information such as road conditions, status lights, among others. The centralized location of a single driver on SDN, allows the driver to make better decisions based on the global vision that has on the network. However, as the driver is usually far from the vehicle, this architecture tends to produce a significant latency operations.
Sudheera et al. They present a model location driver level RSU Software Defined Vehicular Network (SDVN) as a problem entire quadratic programming, considering factors such as the number of drivers, latency, the importance of the geographical location of the RSU, distribution workload and vehicle statistics about the location of the RSU. Propose a hierarchical distributed architecture SDVN (HD-SDVN, for its acronym in English) with a model location of drivers to comply delay restriction in vehicular networks.
 
 
They applied the model in a simplified version of the map of campus of Nanyang Technological University in Singapore. The map is covered with a total of 19 RSUs. They considered decision variables 381 and 722 inequality constraints and equality constraints 39. They used CPLEX Optimizer software to solve placement problems under different delay constraints
The results showed that the proposed locations optimized drivers with lower latency compared to existing and conventional SDVN VANET.[USTA]








\cite{XiQu14}:Xia et al. They focused on the use of spectral clustering method (Spectral Clustering) for dividing a WAN topology SDN several small domains and how to place the controller with low latency (latency) and high reliability (reliability) in each domain SDN. At work, they assumed that communication between controllers has been resolved perfectly. Metrics location problem of SDN controller were defined so as to minimize propagation delays (propagation delays), load balances (balances the load) and ensures reliability (reliability) of the controller.
Performance driver location proposed by the authors was compared to other locations, they created a set of scenarios advanced testing to verify and performed better in evaluating the optimized location of the average latency and location optimized latency in the worst cases. They used the Internet2 OS3E as topology evaluation.
They tested the effectiveness of the proposed solution with a comparative performance analysis Spectral Cluster and placing the average latency.[USTA]


\cite{SaHi17}: Sallahi and St Hilaire have an expansion model for the problem location in SDN controller when the network is modified. Given any existing network infrastructure and a list of switches that must be added to the network, the model will find how many, where and what drivers also install how to reorganize the network to minimize the cost of renovation. The proposed model can be used to plan a new network from scratch or upgrade any existing network. The goal is to minimize the cost of network expansion and find the cheapest way to upgrade. This includes the cost of installing or removing drivers, the cost of adding or removing links between the controllers and between controllers or switches;
The authors use as a starting point the mathematical and modified to consider scenarios can expansion. To develop the model, it requires the following inputs: i) The positions of all switches and the amount of traffic generated by the controller. The amount of traffic refers to the maximum traffic plus an additional safety margin to allow for some growth. ii) The different types of links (defined by bandwidth and cost) that can be used to design / network expansion. iii) The different types of controllers (defined by the number of ports, capacity and cost) that can be installed. iv) The maximum tolerable flow configuration latency between switches and controllers to support multiple applications / services. v) The existing SDN topology.
6) The cost of disposal / reallocation of existing equipment (link or controller).
For evaluation model, consider it a full mesh topology. Consist 20, and switches 25 and 30 for each set of switches, also generated randomly controller 40 possible locations. The results show that the expansion when adding more switches to the network, you may need more drivers to support the additional load. The more expensive delete an existing link, the less likely that changes in the initial network. However, in some situations, the links must be removed to meet the restrictions regardless of the cost. As for the time of the CPU time it takes to find the solutions it is considerably lower compared with the placement problem.[USTA]




\cite{ZhGi17}:Zhang et al. They investigated the location of the drivers through the nodes of the network, considering the delays (delays) to switch controller and controller to controller (required to synchronize shared data structures) for the WAN. In addition, the propagation latency between multiple controllers was also taken into account. To explore all possible offsets in the switch-controller and controller-controller plans, they adopted an optimal algorithm (called Exa-Place) to list exhaustively all possible locations of drivers and get all Pareto-optimal locations. For small networks, the number of possible locations is not so great and so Exa-Place is computationally feasible, for larger networks the authors designed an approximate algorithm to find the Pareto frontier. It also formalized the problem ILP to find the optimum location to minimize the reaction time (defined as the perceived latency switch when a new network event is generated) and designed an algorithm approach to solve the problem ILP and assess its performance in real ISP networks. In the formulation, the aim was also to find the best teacher to assign each switch, without assuming that the master of a switch controller was the closest to this driver controller. The location of the controller that acts as a master in the algorithm consensus has a strong impact on the perceived reactivity switches. They formalized the problem ILP to find the optimum location to minimize the reaction time (defined as the perceived latency switch when a new network event is generated) and designed an algorithm approach to solve the problem ILP and evaluate their performance in networks real ISP. In the formulation, the aim was also to find the best teacher to assign each switch, without assuming that the master of a switch controller was the closest to this driver controller. The location of the controller that acts as a master in the algorithm consensus has a strong impact on the perceived reactivity switches. They formalized the problem ILP to find the optimum location to minimize the reaction time (defined as the perceived latency switch when a new network event is generated) and designed an algorithm approach to solve the problem ILP and evaluate their performance in networks real ISP. In the formulation, the aim was also to find the best teacher to assign each switch, without assuming that the master of a switch controller was the closest to this driver controller. The location of the controller that acts as a master in the algorithm consensus has a strong impact on the perceived reactivity switches.
the Internet topologies topology zoo and Highwinds ISP were used to evaluate the proposal, the results showed that an optimized choice of the controller acting as data owner can improve the reaction time between 2 and 4 times, compared to the scenario does not consider . It was shown that connecting a switch to the nearest driver is not always optimal, or minimize the reaction time perceived switches, taking into account the overhead due to traffic coordination between controllers.[USTA]


\cite{HuLu16}:Hu. et al. They addressed the problem of location considering latency and load balancing and modeled as a binary integer problem (BIP), on the stage where the controller is located statically controller. The goal is to minimize the average latency and latency worst case when the load is balanced between the controllers (pure latency), then analyzed the cost of latency to consider load balancing. They used the software CPLEX optimizer to evaluate the increase in latency to consider load balancing. They took 10 topologies with different sizes of SND-lib [9] to evaluate the model. The experiment results showed that can achieve a balanced level control with a small increase to optimal latency calculated by pure latency. In some cases, the latency problem can be solved and optimal load balancing simultaneously (without increasing latency). For large-scale topologies, find the optimal location will need a powerful computer and take a long time.





\section{Support}

Table for different papers, with abstract, conclusion and problem statement:

https://lite.framacalc.org/8Wsn7JJBfH

Table for papers classification:

https://lite.framacalc.org/auBmGx08yd

New classification

https://lite.framacalc.org/oADf7JaMYF

new table 
https://docs.google.com/spreadsheets/d/1GnxnGbTXQAAec4c3FVZlig5K0PExLncS9XG-40IRyRw/edit#gid=0










%\begin{table}[]
%\centering
%\caption{My caption}
%\label{my-label}
%\begin{tabular}{@{}|l|l|l|l|l|l|l|@{}}
%\toprule
%\multicolumn{2}{|l|}{Optimization objective} & Paper & Constraint & Technique & Test & Details \\ \midrule
%\multicolumn{2}{|l|}{\multirow{5}{*}{Latency}} &  &  &  &  &  \\ \cmidrule(l){3-7} 
%\multicolumn{2}{|l|}{} &  &  &  &  &  \\ \cmidrule(l){3-7} 
%\multicolumn{2}{|l|}{} &  &  &  &  &  \\ \cmidrule(l){3-7} 
%\multicolumn{2}{|l|}{} &  &  &  &  &  \\ \cmidrule(l){3-7} 
%\multicolumn{2}{|l|}{} &  &  &  &  &  \\ \midrule
%\multirow{9}{*}{Multi Objective} & Node-node, node-cntrl, load balancing &  &  &  &  &  \\ \cmidrule(l){2-7} 
% & node-cntrl, switch weight, load balancing &  &  &  &  &  \\ \cmidrule(l){2-7} 
% & node-cntrl, inter cntrl, load balancing &  &  &  &  &  \\ \cmidrule(l){2-7} 
% & node-cntrl, inter cntrl, load balancing &  &  &  &  &  \\ \cmidrule(l){2-7} 
% & controller load and network radius &  &  &  &  &  \\ \cmidrule(l){2-7} 
% & computational delay and controller load &  &  &  &  &  \\ \cmidrule(l){2-7} 
% & node-cntrl, inter cntrl, load balancing &  &  &  &  &  \\ \cmidrule(l){2-7} 
% & propagation delay and load balancing &  &  &  &  &  \\ \cmidrule(l){2-7} 
% & time and cost &  &  &  &  &  \\ \midrule
%\multicolumn{2}{|l|}{\multirow{3}{*}{Resilience}} &  &  &  &  &  \\ \cmidrule(l){3-7} 
%\multicolumn{2}{|l|}{} &  &  &  &  &  \\ \cmidrule(l){3-7} 
%\multicolumn{2}{|l|}{} &  &  &  &  &  \\ \midrule
%\multicolumn{2}{|l|}{Cummunication cost} &  &  &  &  &  \\ \midrule
%\multicolumn{2}{|l|}{\multirow{3}{*}{Reliability}} &  &  &  &  &  \\ \cmidrule(l){3-7} 
%\multicolumn{2}{|l|}{} &  &  &  &  &  \\ \cmidrule(l){3-7} 
%\multicolumn{2}{|l|}{} &  &  &  &  &  \\ \bottomrule
%\end{tabular}
%\end{table}

\medskip

\bibliographystyle{unsrt}%Used BibTeX style is unsrt
\bibliography{bib_survey}

\end{document}
